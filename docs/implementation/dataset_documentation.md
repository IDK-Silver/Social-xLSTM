# Dataset æ¨¡çµ„æ–‡æª”

## æ¨¡çµ„æ¦‚è¿°

`social_xlstm.dataset` æ¨¡çµ„è² è²¬äº¤é€šæ•¸æ“šçš„å®Œæ•´è™•ç†æµç¨‹ï¼Œå¾åŸå§‹è³‡æ–™è¼‰å…¥åˆ°æ·±åº¦å­¸ç¿’æ¨¡å‹çš„è¼¸å…¥æº–å‚™ã€‚æ­¤æ¨¡çµ„å¯¦ç¾äº†é«˜æ•ˆçš„æ•¸æ“šè™•ç†ç®¡ç·šï¼Œæ”¯æ´å¤§è¦æ¨¡æ™‚é–“åºåˆ—äº¤é€šæ•¸æ“šçš„é è™•ç†ã€ç‰¹å¾µæå–å’Œæ‰¹æ¬¡è¼‰å…¥ã€‚

## ğŸ“¦ æ¨¡çµ„æ¶æ§‹

æœ¬æ¨¡çµ„æ¡ç”¨çµæ§‹åŒ–è¨­è¨ˆï¼Œåˆ†ç‚ºå››å€‹ä¸»è¦å­å¥—ä»¶ï¼š

```
social_xlstm.dataset/
â”œâ”€â”€ config/          # é…ç½®ç®¡ç†
â”‚   â””â”€â”€ base.py     # TrafficDatasetConfig, TrafficHDF5Config
â”œâ”€â”€ core/           # æ ¸å¿ƒæ•¸æ“šæ“ä½œ
â”‚   â”œâ”€â”€ processor.py    # TrafficDataProcessor
â”‚   â”œâ”€â”€ timeseries.py   # TrafficTimeSeries
â”‚   â””â”€â”€ datamodule.py   # TrafficDataModule
â”œâ”€â”€ storage/        # å­˜å„²èˆ‡æŒä¹…åŒ–
â”‚   â”œâ”€â”€ h5_converter.py # HDF5 è½‰æ›å™¨
â”‚   â”œâ”€â”€ h5_reader.py    # HDF5 è®€å–å™¨
â”‚   â””â”€â”€ feature.py      # TrafficFeature dataclass
â””â”€â”€ utils/          # å·¥å…·å‡½æ•¸
    â”œâ”€â”€ json_utils.py   # JSON è™•ç†
    â”œâ”€â”€ xml_utils.py    # XML è½‰æ›
    â””â”€â”€ zip_utils.py    # å£“ç¸®æª”æ¡ˆè™•ç†
```

## ğŸš€ å¿«é€Ÿé–‹å§‹

### åŸºæœ¬ä½¿ç”¨ç¯„ä¾‹

```python
# 1. å°å…¥æ ¸å¿ƒé¡åˆ¥
from social_xlstm.dataset import TrafficDatasetConfig, TrafficDataModule
from social_xlstm.dataset.storage import create_traffic_hdf5

# 2. å‰µå»º HDF5 æ•¸æ“šæ–‡ä»¶
create_traffic_hdf5(
    source_dir="data/json",
    output_path="data/traffic.h5",
    selected_vdids=["VD-001", "VD-002"]
)

# 3. é…ç½®æ•¸æ“šé›†
config = TrafficDatasetConfig(
    hdf5_path="data/traffic.h5",
    sequence_length=60,
    prediction_length=15,
    normalize=True,
    batch_size=32
)

# 4. å‰µå»ºæ•¸æ“šæ¨¡çµ„
data_module = TrafficDataModule(config)
data_module.setup()

# 5. ç²å–æ•¸æ“šè¼‰å…¥å™¨
train_loader = data_module.train_dataloader()
val_loader = data_module.val_dataloader()
```

## æ ¸å¿ƒçµ„ä»¶

### 1. é…ç½®ç®¡ç† (`config/`)

#### TrafficDatasetConfig
**ä½ç½®**: `social_xlstm.dataset.config.base`

**åŠŸèƒ½**: çµ±ä¸€ç®¡ç†æ•¸æ“šé›†é…ç½®åƒæ•¸

**ä¸»è¦é…ç½®é …**:
- `hdf5_path`: HDF5 æ•¸æ“šæ–‡ä»¶è·¯å¾‘
- `sequence_length`: è¼¸å…¥åºåˆ—é•·åº¦
- `prediction_length`: é æ¸¬åºåˆ—é•·åº¦
- `normalize`: æ˜¯å¦æ­£è¦åŒ–æ•¸æ“š
- `batch_size`: æ‰¹æ¬¡å¤§å°
- `num_workers`: æ•¸æ“šè¼‰å…¥å™¨å·¥ä½œç·šç¨‹æ•¸
- `train_split`: è¨“ç·´é›†æ¯”ä¾‹
- `val_split`: é©—è­‰é›†æ¯”ä¾‹

**ä½¿ç”¨ç¯„ä¾‹**:
```python
from social_xlstm.dataset.config import TrafficDatasetConfig

config = TrafficDatasetConfig(
    hdf5_path="data/traffic.h5",
    sequence_length=60,
    prediction_length=15,
    normalize=True,
    normalization_method="standard",
    batch_size=32,
    num_workers=4
)
```

#### TrafficHDF5Config
**åŠŸèƒ½**: HDF5 è½‰æ›é…ç½®ç®¡ç†

**ä¸»è¦é…ç½®é …**:
- `compression`: å£“ç¸®æ–¹å¼ ("gzip", "lzf")
- `chunk_size`: æ•¸æ“šå¡Šå¤§å°
- `selected_vdids`: é¸å®šçš„ VD ID åˆ—è¡¨
- `time_range`: æ™‚é–“ç¯„åœéæ¿¾ (è©³è¦‹ä¸‹æ–¹èªªæ˜)

#### time_range åƒæ•¸è©³è§£

**ç”¨é€”**: æŒ‡å®šæ•¸æ“šè™•ç†çš„æ™‚é–“ç¯„åœéæ¿¾ï¼Œæ§åˆ¶ HDF5 è½‰æ›éç¨‹ä¸­è™•ç†çš„æ•¸æ“šæ™‚é–“çª—å£ã€‚

**é¡å‹**: `Optional[Tuple[str, str]]`

**æ ¼å¼è¦æ±‚**: `"YYYY-MM-DD_HH-MM-SS,YYYY-MM-DD_HH-MM-SS"`
- é–‹å§‹æ™‚é–“å’ŒçµæŸæ™‚é–“ç”¨é€—è™Ÿåˆ†éš”
- æ™‚é–“æ ¼å¼ï¼šå¹´-æœˆ-æ—¥_æ™‚-åˆ†-ç§’
- ç¯„ä¾‹ï¼š`"2025-03-18_00-00-00,2025-03-18_23-59-59"`

**è¡Œç‚ºèªªæ˜**:
- `null` æˆ– `None`: è™•ç†æ‰€æœ‰å¯ç”¨æ•¸æ“šï¼ˆç„¡æ™‚é–“éæ¿¾ï¼‰- æ¨è–¦ç”¨æ–¼ç”Ÿç”¢ç’°å¢ƒ
- å…·é«”æ™‚é–“ç¯„åœ: åƒ…è™•ç†æŒ‡å®šæ™‚é–“æ®µå…§çš„æ•¸æ“š - é©åˆé–‹ç™¼æ¸¬è©¦

**å¯¦ç¾ä½ç½®**: `src/social_xlstm/dataset/storage/h5_converter.py:419-425`

**é…ç½®ç¯„ä¾‹**:
```yaml
# é–‹ç™¼ç’°å¢ƒ - è™•ç†ç‰¹å®šæ™‚é–“ç¯„åœ
time_range: "2025-03-18_00-00-00,2025-03-18_23-59-59"

# ç”Ÿç”¢ç’°å¢ƒ - è™•ç†æ‰€æœ‰æ•¸æ“š
time_range: null
```

**ç›¸é—œé…ç½®æ–‡ä»¶**:
- é–‹ç™¼é…ç½®: `cfgs/snakemake/dev.yaml`
- ç”Ÿç”¢é…ç½®: `cfgs/snakemake/default.yaml`

### 2. æ•¸æ“šç‰¹å¾µ (`storage/feature.py`)

**åŠŸèƒ½**: å®šç¾©æ¨™æº–åŒ–çš„äº¤é€šç‰¹å¾µæ•¸æ“šçµæ§‹

**æ ¸å¿ƒé¡åˆ¥**:
- `TrafficFeature`: äº¤é€šç‰¹å¾µçš„æ•¸æ“šé¡åˆ¥

**ä¸»è¦åŠŸèƒ½**:
- å°è£äº”ç¨®æ ¸å¿ƒäº¤é€šæŒ‡æ¨™ï¼šå¹³å‡é€Ÿåº¦ã€ç¸½äº¤é€šé‡ã€å¹³å‡å æœ‰ç‡ã€é€Ÿåº¦æ¨™æº–å·®ã€è»Šé“æ•¸
- æä¾›å­—æ®µåç¨±å¸¸é‡ï¼Œé¿å…å­—ä¸²ç¡¬ç·¨ç¢¼
- æ”¯æ´å­—å…¸è½‰æ›å’Œå­—æ®µåç¨±æŸ¥è©¢

**ä½¿ç”¨å ´æ™¯**:
```python
from social_xlstm.dataset.storage import TrafficFeature

# å‰µå»ºäº¤é€šç‰¹å¾µ
feature = TrafficFeature(
    avg_speed=65.5,
    total_volume=120,
    avg_occupancy=15.2,
    speed_std=8.3,
    lane_count=3
)

# ç²å–å­—æ®µåç¨±
field_names = TrafficFeature.get_field_names()
feature_dict = feature.to_dict()
```

**è¨­è¨ˆè©•ä¼°**:
- âœ… **å„ªé»**: çµæ§‹æ¸…æ™°ï¼Œé¡å‹å®‰å…¨ï¼Œæ˜“æ–¼ç¶­è­·
- âœ… **å„ªé»**: å­—æ®µåç¨±å¸¸é‡é¿å…æ‹¼å¯«éŒ¯èª¤
- âœ… **æ”¹é€²**: å·²ç§»è‡³ storage å­å¥—ä»¶ï¼Œè·è²¬æ›´æ¸…æ™°

### 3. æ ¸å¿ƒæ•¸æ“šæ“ä½œ (`core/`)

#### TrafficDataProcessor (`core/processor.py`)
**åŠŸèƒ½**: æ•¸æ“šé è™•ç†å’Œæ­£è¦åŒ–

**ä¸»è¦åŠŸèƒ½**:
- å¤šç¨®æ­£è¦åŒ–æ–¹æ³•ï¼ˆæ¨™æº–åŒ–ã€æœ€å°-æœ€å¤§ï¼‰
- ç¼ºå¤±å€¼è™•ç†ï¼ˆé›¶å¡«å……ã€å‰å‘å¡«å……ã€æ’å€¼ï¼‰
- æ™‚é–“ç‰¹å¾µå·¥ç¨‹ï¼ˆå°æ™‚ã€æ˜ŸæœŸã€æœˆä»½çš„å¾ªç’°ç·¨ç¢¼ï¼‰
- åºåˆ—æ•¸æ“šçª—å£åˆ‡ç‰‡

**ä½¿ç”¨ç¯„ä¾‹**:
```python
from social_xlstm.dataset.core import TrafficDataProcessor

processor = TrafficDataProcessor(
    normalize=True,
    normalization_method="standard",
    missing_value_strategy="forward_fill",
    add_time_features=True
)

# è™•ç†æ•¸æ“š
processed_data = processor.process_data(raw_data)
```

#### TrafficTimeSeries (`core/timeseries.py`)
**åŠŸèƒ½**: PyTorch æ™‚é–“åºåˆ—æ•¸æ“šé›†

**ä¸»è¦åŠŸèƒ½**:
- æ™‚é–“åºåˆ—çª—å£åˆ‡ç‰‡
- å‹•æ…‹åºåˆ—é•·åº¦æ”¯æ´
- è¨˜æ†¶é«”é«˜æ•ˆçš„æ•¸æ“šè¼‰å…¥
- å¤šVDæ•¸æ“šæ”¯æ´

**ä½¿ç”¨ç¯„ä¾‹**:
```python
from social_xlstm.dataset.core import TrafficTimeSeries

dataset = TrafficTimeSeries(
    hdf5_path="data/traffic.h5",
    sequence_length=60,
    prediction_length=15,
    vdids=["VD-001", "VD-002"],
    processor=processor
)
```

#### TrafficDataModule (`core/datamodule.py`)
**åŠŸèƒ½**: PyTorch Lightning æ•¸æ“šæ¨¡çµ„

**ä¸»è¦åŠŸèƒ½**:
- è‡ªå‹•è¨“ç·´/é©—è­‰/æ¸¬è©¦é›†åˆ†å‰²
- æ•¸æ“šè¼‰å…¥å™¨ç®¡ç†
- åˆ†æ•£å¼è¨“ç·´æ”¯æ´
- å‹•æ…‹æ‰¹æ¬¡å¤§å°èª¿æ•´

**ä½¿ç”¨ç¯„ä¾‹**:
```python
from social_xlstm.dataset.core import TrafficDataModule
from social_xlstm.dataset.config import TrafficDatasetConfig

config = TrafficDatasetConfig(
    hdf5_path="data/traffic.h5",
    sequence_length=60,
    prediction_length=15,
    batch_size=32
)

data_module = TrafficDataModule(config)
data_module.setup()

# ç²å–æ•¸æ“šè¼‰å…¥å™¨
train_loader = data_module.train_dataloader()
val_loader = data_module.val_dataloader()
test_loader = data_module.test_dataloader()
```

**è¨­è¨ˆè©•ä¼°**:
- âœ… **å„ªé»**: è·è²¬åˆ†é›¢ï¼Œçµæ§‹æ¸…æ™°
- âœ… **å„ªé»**: æ”¯æ´ PyTorch Lightning æœ€ä½³å¯¦è¸
- âœ… **æ”¹é€²**: å·²é‡æ§‹ç‚ºç¨ç«‹æ¨¡çµ„ï¼Œæ˜“æ–¼ç¶­è­·

### 4. å­˜å„²èˆ‡æŒä¹…åŒ– (`storage/`)

#### TrafficHDF5Converter (`storage/h5_converter.py`)
**åŠŸèƒ½**: JSON åˆ° HDF5 æ ¼å¼è½‰æ›

**æ ¸å¿ƒé¡åˆ¥**:
- `TrafficHDF5Converter`: HDF5 è½‰æ›å™¨
- `TrafficFeatureExtractor`: ç‰¹å¾µæå–å™¨

**ä¸»è¦åŠŸèƒ½**:
- æ‰¹æ¬¡è™•ç† JSON æ•¸æ“šè½‰æ›ç‚º HDF5
- æ™ºèƒ½æª¢æŸ¥ï¼ˆé…ç½®ä¸€è‡´æ€§ã€æ–‡ä»¶æ›´æ–°æ™‚é–“ï¼‰
- å£“ç¸®å­˜å„²å’Œå¢é‡æ›´æ–°
- è»Šé“ç´šåˆ¥ç‰¹å¾µèšåˆ

**ä½¿ç”¨ç¯„ä¾‹**:
```python
from social_xlstm.dataset.storage import TrafficHDF5Converter, TrafficHDF5Config

config = TrafficHDF5Config(
    compression="gzip",
    chunk_size=1000,
    selected_vdids=["VD-001", "VD-002"]
)

converter = TrafficHDF5Converter(config)
converter.convert_directory(
    source_dir="data/json",
    output_path="data/traffic.h5",
    overwrite=False
)
```

#### TrafficHDF5Reader (`storage/h5_reader.py`)
**åŠŸèƒ½**: HDF5 æ•¸æ“šè®€å–å’ŒæŸ¥è©¢

**ä¸»è¦åŠŸèƒ½**:
- é«˜æ•ˆçš„ HDF5 æ•¸æ“šè®€å–
- æ™‚é–“ç¯„åœæŸ¥è©¢
- VD ç´šåˆ¥æ•¸æ“šéæ¿¾
- è¨˜æ†¶é«”æ•ˆç‡å„ªåŒ–

**ä½¿ç”¨ç¯„ä¾‹**:
```python
from social_xlstm.dataset.storage import TrafficHDF5Reader

reader = TrafficHDF5Reader("data/traffic.h5")

# è®€å–ç‰¹å®š VD æ•¸æ“š
data = reader.read_vd_data(
    vdid="VD-001",
    start_time="2023-01-01",
    end_time="2023-01-31"
)

# ç²å–å¯ç”¨ VD åˆ—è¡¨
available_vdids = reader.get_available_vdids()
```

#### ä¾¿æ·å‡½æ•¸
```python
from social_xlstm.dataset.storage import create_traffic_hdf5

# ä¸€éµå‰µå»º HDF5 æ–‡ä»¶
create_traffic_hdf5(
    source_dir="data/json",
    output_path="data/traffic.h5",
    selected_vdids=["VD-001", "VD-002"],
    overwrite=False
)
```

**è¨­è¨ˆè©•ä¼°**:
- âœ… **å„ªé»**: è½‰æ›å™¨å’Œè®€å–å™¨åˆ†é›¢ï¼Œè·è²¬æ¸…æ™°
- âœ… **å„ªé»**: æ™ºèƒ½æª¢æŸ¥æ©Ÿåˆ¶ï¼Œé¿å…é‡è¤‡è½‰æ›
- âœ… **å„ªé»**: æ”¯æ´å¤§è¦æ¨¡æ•¸æ“šè™•ç†å’Œå£“ç¸®
- âœ… **æ”¹é€²**: å·²åˆ†é›¢ç‚ºç¨ç«‹æ¨¡çµ„ï¼Œæ˜“æ–¼ç¶­è­·

### 5. å·¥å…·å‡½æ•¸ (`utils/`)

#### JSON å·¥å…· (`utils/json_utils.py`)
**åŠŸèƒ½**: äº¤é€šæ•¸æ“š JSON æ ¼å¼è™•ç†

**æ ¸å¿ƒé¡åˆ¥**:
- `VDInfo`: è»Šè¼›åµæ¸¬å™¨è³‡è¨Š
- `VDLiveList`: å³æ™‚äº¤é€šæ•¸æ“šåˆ—è¡¨
- `VD`, `VehicleData`, `LaneData`: æ•¸æ“šçµæ§‹é¡åˆ¥

**ä¸»è¦åŠŸèƒ½**:
- çµæ§‹åŒ–è§£æäº¤é€š JSON æ•¸æ“š
- VDID æ­£è¦åŒ–è™•ç†
- è»Šé“å’Œè»Šè¼›æ•¸æ“šå°è£

**ä½¿ç”¨ç¯„ä¾‹**:
```python
from social_xlstm.dataset.utils import VDInfo, VDLiveList

# è§£æ VD è³‡è¨Š
vd_info = VDInfo.from_json(vd_info_json)
vd_dict = vd_info.to_dict()

# è™•ç†å³æ™‚æ•¸æ“š
live_list = VDLiveList.from_json(live_data_json)
filtered_data = live_list.filter_by_vdids(["VD-001", "VD-002"])
```

#### XML å·¥å…· (`utils/xml_utils.py`)
**åŠŸèƒ½**: XML åˆ° JSON æ ¼å¼è½‰æ›

**ä¸»è¦åŠŸèƒ½**:
- XML æ•¸æ“šè§£æ
- çµæ§‹åŒ–è½‰æ›ç‚º JSON
- éŒ¯èª¤è™•ç†å’Œé©—è­‰

**ä½¿ç”¨ç¯„ä¾‹**:
```python
from social_xlstm.dataset.utils import VDList_xml_to_Json

# è½‰æ› XML åˆ° JSON
json_data = VDList_xml_to_Json(xml_file_path)
```

#### ZIP å·¥å…· (`utils/zip_utils.py`)
**åŠŸèƒ½**: å£“ç¸®æª”æ¡ˆè™•ç†

**ä¸»è¦åŠŸèƒ½**:
- æ”¯æ´å¤šç¨®å£“ç¸®æ ¼å¼ï¼ˆZIP, 7zï¼‰
- è‡ªå‹•è§£å£“ç¸®
- æ™‚é–“æˆ³è§£æ
- éŒ¯èª¤è™•ç†

**ä½¿ç”¨ç¯„ä¾‹**:
```python
from social_xlstm.dataset.utils import extract_archive, parse_time_from_filename

# è§£å£“ç¸®æª”æ¡ˆ
extract_archive("data.zip", "output_dir")

# è§£ææ™‚é–“æˆ³
timestamp = parse_time_from_filename("data_20230101_1200.zip")
```

**è¨­è¨ˆè©•ä¼°**:
- âœ… **å„ªé»**: å®Œæ•´çš„æ•¸æ“šçµæ§‹å®šç¾©
- âœ… **å„ªé»**: æ”¯æ´ JSON åºåˆ—åŒ–/ååºåˆ—åŒ–
- âœ… **å„ªé»**: å·¥å…·å‡½æ•¸çµ„ç¹”æ¸…æ™°ï¼Œæ˜“æ–¼ä½¿ç”¨
- âœ… **æ”¹é€²**: å·²ç§»è‡³ utils å­å¥—ä»¶ï¼Œè·è²¬æ›´æ˜ç¢º

## ğŸ”„ API åƒè€ƒ

### ä¸»è¦å°å…¥æ–¹å¼

```python
# ä¸»è¦é¡åˆ¥ (å¾ä¸»æ¨¡çµ„å°å…¥)
from social_xlstm.dataset import (
    TrafficDatasetConfig,
    TrafficDataModule,
    TrafficTimeSeries,
    TrafficDataProcessor
)

# å­˜å„²ç›¸é—œ (å¾å­æ¨¡çµ„å°å…¥)
from social_xlstm.dataset.storage import (
    TrafficFeature,
    TrafficHDF5Converter,
    TrafficHDF5Reader,
    create_traffic_hdf5
)

# å·¥å…·å‡½æ•¸ (å¾å­æ¨¡çµ„å°å…¥)
from social_xlstm.dataset.utils import (
    VDInfo,
    VDLiveList,
    extract_archive,
    VDList_xml_to_Json
)
```

### å®Œæ•´å·¥ä½œæµç¨‹

```python
# 1. æ•¸æ“šé è™•ç†
from social_xlstm.dataset.storage import create_traffic_hdf5
from social_xlstm.dataset.utils import extract_archive

# è§£å£“ç¸®åŸå§‹æ•¸æ“š
extract_archive("traffic_data.zip", "data/raw")

# è½‰æ›ç‚º HDF5
create_traffic_hdf5(
    source_dir="data/raw",
    output_path="data/traffic.h5",
    selected_vdids=["VD-001", "VD-002", "VD-003"]
)

# 2. é…ç½®æ•¸æ“šé›†
from social_xlstm.dataset import TrafficDatasetConfig

config = TrafficDatasetConfig(
    hdf5_path="data/traffic.h5",
    sequence_length=60,
    prediction_length=15,
    normalize=True,
    normalization_method="standard",
    missing_value_strategy="forward_fill",
    add_time_features=True,
    batch_size=32,
    num_workers=4,
    train_split=0.7,
    val_split=0.2
)

# 3. å‰µå»ºæ•¸æ“šæ¨¡çµ„
from social_xlstm.dataset import TrafficDataModule

data_module = TrafficDataModule(config)
data_module.setup()

# 4. ä½¿ç”¨æ–¼è¨“ç·´
import pytorch_lightning as pl

trainer = pl.Trainer(
    max_epochs=100,
    accelerator="gpu",
    devices=1
)

# å‡è¨­æœ‰ä¸€å€‹æ¨¡å‹
trainer.fit(model, data_module)
```

## ğŸ“Š æ•ˆèƒ½èˆ‡å„ªåŒ–

### è¨˜æ†¶é«”å„ªåŒ–
- **HDF5 å£“ç¸®**: ä½¿ç”¨ gzip å£“ç¸®ï¼Œç¯€çœ 60-70% å„²å­˜ç©ºé–“
- **åˆ†å¡Šè®€å–**: æŒ‰éœ€è¼‰å…¥æ•¸æ“šï¼Œé™ä½è¨˜æ†¶é«”ä½¿ç”¨
- **æ•¸æ“šé å–**: ä½¿ç”¨å¤šç·šç¨‹é å…ˆè¼‰å…¥æ•¸æ“š

### è™•ç†æ•ˆèƒ½
- **æ‰¹æ¬¡è™•ç†**: æ”¯æ´å¤§æ‰¹æ¬¡æ•¸æ“šè½‰æ›
- **ä¸¦è¡Œè¼‰å…¥**: å¤šé€²ç¨‹æ•¸æ“šè¼‰å…¥å™¨
- **å¿«å–æ©Ÿåˆ¶**: æ™ºèƒ½æª¢æŸ¥é¿å…é‡è¤‡è½‰æ›

### å¯æ“´å±•æ€§
- **å¤š VD æ”¯æ´**: åŒæ™‚è™•ç†å¤šå€‹è»Šè¼›åµæ¸¬å™¨
- **æ™‚é–“ç¯„åœéæ¿¾**: éˆæ´»çš„æ™‚é–“ç¯„åœé¸æ“‡
- **å‹•æ…‹é…ç½®**: é‹è¡Œæ™‚èª¿æ•´åƒæ•¸

## ğŸ”§ æ•…éšœæ’é™¤

### å¸¸è¦‹å•é¡Œ

#### 1. HDF5 æ–‡ä»¶æå£
```python
# æª¢æŸ¥ HDF5 æ–‡ä»¶å®Œæ•´æ€§
from social_xlstm.dataset.storage import TrafficHDF5Reader

reader = TrafficHDF5Reader("data/traffic.h5")
try:
    vdids = reader.get_available_vdids()
    print(f"å¯ç”¨çš„ VD IDs: {vdids}")
except Exception as e:
    print(f"HDF5 æ–‡ä»¶å¯èƒ½æå£: {e}")
```

#### 2. è¨˜æ†¶é«”ä¸è¶³
```python
# æ¸›å°‘æ‰¹æ¬¡å¤§å°å’Œå·¥ä½œç·šç¨‹
config = TrafficDatasetConfig(
    batch_size=16,  # æ¸›å°‘æ‰¹æ¬¡å¤§å°
    num_workers=2,  # æ¸›å°‘å·¥ä½œç·šç¨‹
    sequence_length=30  # æ¸›å°‘åºåˆ—é•·åº¦
)
```

#### 3. æ­£è¦åŒ–å•é¡Œ
```python
# æª¢æŸ¥æ­£è¦åŒ–çµ±è¨ˆ
from social_xlstm.dataset.core import TrafficDataProcessor

processor = TrafficDataProcessor(normalize=True)
processor.fit(train_data)
print(f"å‡å€¼: {processor.mean_}")
print(f"æ¨™æº–å·®: {processor.std_}")
```

## æ•´é«”è©•ä¼°

### âœ… å„ªé»
1. **çµæ§‹åŒ–æ¶æ§‹**: æ¸…æ™°çš„æ¨¡çµ„åˆ†é›¢å’Œè·è²¬åŠƒåˆ†
2. **å®Œæ•´çš„æ•¸æ“šæµç¨‹**: å¾åŸå§‹æ•¸æ“šåˆ°æ¨¡å‹è¼¸å…¥çš„å®Œæ•´è™•ç†
3. **é«˜æ•ˆå­˜å„²**: HDF5 æ ¼å¼æ”¯æ´å¤§è¦æ¨¡æ•¸æ“š
4. **éˆæ´»é…ç½®**: è±å¯Œçš„é…ç½®é¸é …æ»¿è¶³ä¸åŒéœ€æ±‚
5. **PyTorch æ•´åˆ**: å®Œæ•´çš„ PyTorch Lightning æ”¯æ´
6. **æ˜“æ–¼ä½¿ç”¨**: æ¸…æ™°çš„ API å’Œè±å¯Œçš„ä½¿ç”¨ç¯„ä¾‹

### âœ… å·²è§£æ±ºçš„å•é¡Œ
1. **âœ… ä»£ç¢¼çµæ§‹**: å·²é‡æ§‹ç‚ºçµæ§‹åŒ–å­å¥—ä»¶
2. **âœ… è·è²¬åˆ†é›¢**: è½‰æ›å™¨å’Œè®€å–å™¨å·²åˆ†é›¢
3. **âœ… æ­£è¦åŒ–å™¨**: å·²å¯¦ç¾æ­£ç¢ºçš„æ­£è¦åŒ–å™¨å…±äº«æ©Ÿåˆ¶
4. **âœ… æ–‡æª”å®Œæ•´**: æä¾›è©³ç´°çš„ä½¿ç”¨æŒ‡å—å’Œç¯„ä¾‹

### ğŸ”„ æŒçºŒæ”¹é€²
1. **æ•ˆèƒ½å„ªåŒ–**: æŒçºŒå„ªåŒ–æ•¸æ“šè¼‰å…¥é€Ÿåº¦
2. **éŒ¯èª¤è™•ç†**: å¢å¼·ç•°å¸¸è™•ç†å’Œæ—¥èªŒè¨˜éŒ„
3. **æ¸¬è©¦è¦†è“‹**: æå‡æ¸¬è©¦è¦†è“‹ç‡
4. **æ–‡æª”æ›´æ–°**: éš¨åŠŸèƒ½æ›´æ–°ä¿æŒæ–‡æª”åŒæ­¥

## ğŸ¯ ä½¿ç”¨å»ºè­°

### æœ€ä½³å¯¦è¸
1. **é…ç½®ç®¡ç†**: ä½¿ç”¨ `TrafficDatasetConfig` çµ±ä¸€ç®¡ç†æ‰€æœ‰é…ç½®
2. **HDF5 å„ªå…ˆ**: å°å¤§æ•¸æ“šé›†ä½¿ç”¨ HDF5 æ ¼å¼å­˜å„²ï¼Œæå‡è¼‰å…¥é€Ÿåº¦
3. **æ™ºèƒ½æª¢æŸ¥**: åˆ©ç”¨è½‰æ›å™¨çš„æ™ºèƒ½æª¢æŸ¥é¿å…é‡è¤‡è½‰æ›
4. **æ­£è¦åŒ–é¸æ“‡**: æ ¹æ“šæ•¸æ“šç‰¹æ€§é¸æ“‡åˆé©çš„æ­£è¦åŒ–æ–¹æ³•
5. **æ‰¹æ¬¡å¤§å°**: æ ¹æ“š GPU è¨˜æ†¶é«”èª¿æ•´æ‰¹æ¬¡å¤§å°
6. **å¤šé€²ç¨‹è¼‰å…¥**: ä½¿ç”¨ `num_workers` æå‡æ•¸æ“šè¼‰å…¥æ•ˆç‡

### é–‹ç™¼éšæ®µå»ºè­°

#### é–‹ç™¼éšæ®µ
```python
# ä½¿ç”¨è¼ƒå°çš„æ•¸æ“šé›†é€²è¡Œå¿«é€Ÿæ¸¬è©¦
config = TrafficDatasetConfig(
    hdf5_path="data/traffic_small.h5",
    sequence_length=30,
    prediction_length=5,
    batch_size=16,
    num_workers=2
)
```

#### å¯¦é©—éšæ®µ
```python
# ä½¿ç”¨å®Œæ•´é…ç½®é€²è¡Œå¯¦é©—
config = TrafficDatasetConfig(
    hdf5_path="data/traffic.h5",
    sequence_length=60,
    prediction_length=15,
    normalize=True,
    normalization_method="standard",
    add_time_features=True,
    batch_size=32,
    num_workers=4
)
```

#### ç”Ÿç”¢éšæ®µ
```python
# å„ªåŒ–é…ç½®ç”¨æ–¼ç”Ÿç”¢ç’°å¢ƒ
config = TrafficDatasetConfig(
    hdf5_path="data/traffic.h5",
    sequence_length=60,
    prediction_length=15,
    normalize=True,
    batch_size=64,
    num_workers=8,
    pin_memory=True  # GPU è¨“ç·´æ™‚å•Ÿç”¨
)
```

## ğŸ“ˆ ä¸‹ä¸€æ­¥ç™¼å±•

### å³å°‡å¯¦ç¾çš„åŠŸèƒ½
1. **Space-Time ç‰¹å¾µ**: çµåˆåº§æ¨™ç³»çµ±çš„ç©ºé–“ç‰¹å¾µ
2. **Social Pooling**: æ”¯æ´ Social Pooling ç®—æ³•çš„æ•¸æ“šæº–å‚™
3. **å¤šæ¨¡æ…‹æ•¸æ“š**: æ”¯æ´æ›´å¤šäº¤é€šæ•¸æ“šé¡å‹
4. **å¯¦æ™‚è™•ç†**: æ”¯æ´å¯¦æ™‚æ•¸æ“šæµè™•ç†

### èˆ‡å…¶ä»–æ¨¡çµ„çš„æ•´åˆ
- **èˆ‡ `models/` æ¨¡çµ„**: ç‚º xLSTM å’Œ Social Pooling æä¾›æ•¸æ“š
- **èˆ‡ `utils/spatial_coords.py`**: æ•´åˆåº§æ¨™ç³»çµ±é€²è¡Œç©ºé–“ç‰¹å¾µæå–
- **èˆ‡ `evaluation/` æ¨¡çµ„**: æä¾›è©•ä¼°æ•¸æ“šé›†

## ğŸ“ ç¸½çµ

**Dataset æ¨¡çµ„**å·²å®Œæˆé‡æ§‹ï¼Œæä¾›äº†å®Œæ•´ã€é«˜æ•ˆã€çµæ§‹åŒ–çš„äº¤é€šæ•¸æ“šè™•ç†è§£æ±ºæ–¹æ¡ˆã€‚æ¨¡çµ„æ¶æ§‹æ¸…æ™°ï¼ŒåŠŸèƒ½å®Œæ•´ï¼ŒAPI æ˜“ç”¨ï¼Œæº–å‚™å¥½æ”¯æ´ä¸‹ä¸€éšæ®µçš„ **Social Pooling** å’Œ **xLSTM** åŠŸèƒ½é–‹ç™¼ã€‚

**ä¸»è¦æˆå°±**:
- âœ… çµæ§‹åŒ–é‡æ§‹å®Œæˆ
- âœ… å®Œæ•´çš„ API è¨­è¨ˆ
- âœ… é«˜æ•ˆçš„æ•¸æ“šè™•ç†æµç¨‹
- âœ… è±å¯Œçš„é…ç½®é¸é …
- âœ… å®Œæ•´çš„æ–‡æª”å’Œç¯„ä¾‹

**æº–å‚™ç‹€æ…‹**: ğŸš€ **æº–å‚™å°±ç·’**ï¼Œå¯é€²è¡Œæ ¸å¿ƒåŠŸèƒ½é–‹ç™¼ã€‚