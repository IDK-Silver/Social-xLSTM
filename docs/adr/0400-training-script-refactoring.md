# ADR-0400: 訓練腳本重構策略

## 狀態
已實施 (2025-07-09)

## 背景
在修復多VD訓練維度錯誤後，發現 `train_single_vd.py` 和 `train_multi_vd.py` 存在以下問題：
- 90%代碼重複（約400行），嚴重違反DRY原則
- 維護困難，容易產生不一致的錯誤處理和日誌
- 但輸入數據形狀根本不同（單VD: 3D張量 vs 多VD: 4D張量）

## 考慮的選項

### 選項1：完全統一
創建單一腳本 `train_lstm.py` 使用 `--mode` 參數區分

**優點**：
- 消除所有重複代碼
- 單一維護點

**缺點**：
- 邏輯複雜，需要大量條件判斷
- 數據形狀差異難以優雅處理
- 模型創建邏輯差異很大

### 選項2：部分統一（推薦）
提取共用邏輯到模組，保持獨立入口點

**優點**：
- 減少80%重複代碼
- 保持接口清晰，使用者易理解
- 特定邏輯保持獨立，易於維護

**缺點**：
- 仍有約20%代碼重複
- 需要維護三個文件

### 選項3：保持現狀
不做改動，維持兩個獨立腳本

**優點**：
- 無需投入時間
- 避免引入新錯誤

**缺點**：
- 技術債務持續累積
- 維護成本持續增加

## 決策
選擇**選項2：部分統一**

實現方式：
1. 創建 `scripts/train/common.py` 提取共用函數
2. 保持兩個獨立腳本作為清晰的接口
3. 使用函數組合方式共享邏輯

具體提取的共用函數：
- `setup_logging()` - 日誌配置
- `check_conda_environment()` - 環境檢查
- `parse_common_args()` - 共同參數解析
- `create_training_config()` - 訓練配置創建
- `setup_experiment()` - 實驗目錄設置
- `print_training_summary()` - 訓練結果輸出

## 後果

### 正面
- 減少代碼重複約80%（從400行減少到80行）
- 提高可維護性，修改共用邏輯只需一處
- 保持清晰的使用接口，用戶體驗不變
- 為未來的 Social Pooling 訓練腳本奠定基礎

### 負面
- 需要1-2天重構時間
- 仍有20%特定邏輯重複（主要是模型創建）
- 增加一個新的依賴文件

## 實施計劃
1. ✅ 創建 `common.py` 模組
2. ✅ 提取並重構共用函數
3. ✅ 更新兩個訓練腳本使用共用函數
4. ✅ 完整測試確保功能不變
5. ✅ 更新文檔

## 實施結果
- **重構前**: 844行代碼 (單VD: 381行 + 多VD: 463行)
- **重構後**: 899行代碼 (單VD: 187行 + 多VD: 252行 + 共用: 460行)
- **重複代碼減少**: 405行 (約48%的代碼重複被消除)
- **功能測試**: 兩個腳本都能正常運行，輸出與重構前一致
- **創建文件**: `scripts/train/common.py` - 包含所有共用函數

## 參考
- ADR-0300: 確定了架構清理優先的原則
- docs/technical/design_issues_refactoring.md: 詳細問題分析
- docs/technical/known_errors.md: 多VD訓練錯誤記錄