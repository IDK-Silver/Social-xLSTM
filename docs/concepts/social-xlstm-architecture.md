# Social-xLSTM æ¶æ§‹åˆ†ææ–‡æª”

> åŸºæ–¼ä»£ç¢¼æ·±åº¦åˆ†æçš„çœŸå¯¦æ¶æ§‹èªªæ˜  
> å»é™¤è¡“èªåŒ…è£ï¼Œå±•ç¾å¯¦éš›æŠ€è¡“å¯¦ç¾

## ğŸ“‹ æ–‡æª”æ¦‚è¦½

æœ¬æ–‡æª”è©³ç´°åˆ†æäº† Social-xLSTM çš„å¯¦éš›æ¶æ§‹å¯¦ç¾ï¼ŒåŸºæ–¼å°æºä»£ç¢¼çš„æ·±å…¥ç ”ç©¶ï¼Œæ¾„æ¸…äº†æ¶æ§‹è¨­è¨ˆçš„çœŸå¯¦æ©Ÿåˆ¶ï¼Œå»é™¤äº†å¯èƒ½çš„è¡“èªèª¤å°ã€‚

## ğŸ—ï¸ **ç³»çµ±æ¶æ§‹åœ–**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     è¼¸å…¥ï¼šäº¤é€šæ™‚åºæ•¸æ“š                                    â”‚
â”‚              Dict[VD_ID, Tensor[B,T,F]]                                â”‚
â”‚         VD_001:[16,12,6]  VD_002:[16,12,6]  ...  VD_325:[16,12,6]      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   VDXLSTMManager                                        â”‚
â”‚                   (å»¶é²åˆå§‹åŒ–ç®¡ç†å™¨)                                      â”‚
â”‚                                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  â”‚   VD_001    â”‚    â”‚   VD_002    â”‚    ...    â”‚   VD_325    â”‚           â”‚
â”‚  â”‚TrafficXLSTM â”‚    â”‚TrafficXLSTM â”‚           â”‚TrafficXLSTM â”‚           â”‚
â”‚  â”‚6 xLSTM blocksâ”‚   â”‚6 xLSTM blocksâ”‚           â”‚6 xLSTM blocksâ”‚          â”‚
â”‚  â”‚[B,12,6]â†’[B,12,128]â”‚[B,12,6]â†’[B,12,128]â”‚      â”‚[B,12,6]â†’[B,12,128]â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚                                                                         â”‚
â”‚  âš ï¸ é—œéµï¼šåªå–æœ€å¾Œæ™‚é–“æ­¥ [:, -1, :] â†’ [B,128]                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚ Individual Outputs (æœ€å¾Œæ™‚é–“æ­¥)
                          â”‚ Dict[VD_ID, Tensor[B,128]]
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              XLSTMSocialPoolingLayer                                    â”‚
â”‚                     (ç„¡å¯å­¸ç¿’åƒæ•¸)                                        â”‚
â”‚                                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  å°æ¯å€‹ç›®æ¨™VD:                                                       â”‚ â”‚
â”‚  â”‚  1. ç©ºé–“é„°å±…æœç´¢ï¼šdistance â‰¤ 2000m                                    â”‚ â”‚
â”‚  â”‚  2. æ¬Šé‡è¨ˆç®—ï¼š                                                       â”‚ â”‚
â”‚  â”‚     â€¢ mean: w = 1/N                                                 â”‚ â”‚
â”‚  â”‚     â€¢ max: w = one-hot                                              â”‚ â”‚
â”‚  â”‚     â€¢ weighted_mean: w = 1/distance                                 â”‚ â”‚
â”‚  â”‚  3. èšåˆï¼šsocial_context = Î£(neighbor_output Ã— weight)               â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚ Social Contexts
                          â”‚ Dict[VD_ID, Tensor[B,128]]
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ç‰¹å¾µèåˆèˆ‡é æ¸¬                                         â”‚
â”‚                                                                         â”‚
â”‚  å°æ¯å€‹VDä¸¦è¡Œè™•ç†:                                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                     â”‚
â”‚  â”‚Individual   â”‚    â”‚Social       â”‚                                     â”‚
â”‚  â”‚Output[B,128]â”‚ âŠ•  â”‚Context[B,128]â”‚                                    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                     â”‚
â”‚           â”‚                â”‚                                            â”‚
â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                                            â”‚
â”‚                    â–¼                                                    â”‚
â”‚         torch.cat([Individual, Social], dim=-1)                        â”‚
â”‚                    â”‚ [B,256]                                            â”‚
â”‚                    â–¼                                                    â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                 â”‚
â”‚         â”‚      Fusion Layer           â”‚  (32.9K parameters)             â”‚
â”‚         â”‚  Linear(256â†’128) + ReLU     â”‚                                 â”‚
â”‚         â”‚       + Dropout             â”‚                                 â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                 â”‚
â”‚                       â”‚ [B,128]                                         â”‚
â”‚                       â–¼                                                 â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                 â”‚
â”‚         â”‚    Prediction Head          â”‚  (9.4K parameters)              â”‚
â”‚         â”‚  Linear(128â†’64) + ReLU      â”‚                                 â”‚
â”‚         â”‚  Linear(64â†’pred_lenÃ—feat)   â”‚                                 â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                 â”‚
â”‚                       â”‚                                                 â”‚
â”‚                       â–¼                                                 â”‚
â”‚            Final Prediction [B, pred_lenÃ—features]                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

                              â–¼ è¼¸å‡º
          
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       é æ¸¬çµæœ                                           â”‚
â”‚              Dict[VD_ID, Tensor[B,18]]                                 â”‚
â”‚      VD_001:[16,18]    VD_002:[16,18]    ...    VD_325:[16,18]         â”‚
â”‚                                                                         â”‚
â”‚  è¨»ï¼š18 = prediction_length(3) Ã— num_features(6)                        â”‚
â”‚      é æ¸¬æœªä¾†3å€‹æ™‚é–“æ­¥ Ã— 6å€‹ç‰¹å¾µ (PEMS-BAY)                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ” **æ ¸å¿ƒçµ„ä»¶è©³ç´°åˆ†æ**

### 1. VDXLSTMManager - åˆ†æ•£å¼ VD è™•ç†

**åŠŸèƒ½**: ç‚ºæ¯å€‹ VD (Vehicle Detector) ç®¡ç†ç¨ç«‹çš„ xLSTM å¯¦ä¾‹

**é—œéµç‰¹æ€§**:
```python
# å»¶é²åˆå§‹åŒ–æ©Ÿåˆ¶
lazy_init = True  # åªç‚ºå‡ºç¾çš„ VD å‰µå»ºæ¨¡å‹
enable_gradient_checkpointing = False  # è¨˜æ†¶é«”å„ªåŒ–

# å¯¦éš›å‰µå»ºéç¨‹
def _initialize_vd(self, vd_id: str):
    if vd_id not in self.vd_models:
        self.vd_models[vd_id] = TrafficXLSTM(self.xlstm_config)
```

**è¨˜æ†¶é«”ç®¡ç†**:
- å•Ÿå‹•æ™‚ï¼š0 å€‹æ¨¡å‹å¯¦ä¾‹
- é‹è¡Œæ™‚ï¼šæŒ‰éœ€å‰µå»ºï¼Œæœ€çµ‚é”åˆ° 325 å€‹å¯¦ä¾‹
- VRAM ä½¿ç”¨ï¼šæ¼¸é€²ä¸Šå‡å¾Œç©©å®š

### 2. TrafficXLSTM - æ™‚åºç‰¹å¾µæå–

**æ¶æ§‹é…ç½®**:
```python
num_blocks = 6                    # xLSTM å±¤æ•¸
slstm_at = [1, 3]                # sLSTM ä½ç½®
embedding_dim = 128               # çµ±ä¸€è¼¸å‡ºç¶­åº¦
input_size = 6                   # PEMS-BAY ç‰¹å¾µæ•¸
output_size = 6                  # è¼¸å‡ºç‰¹å¾µæ•¸
```

**Block çµæ§‹**:
```
Block 0: mLSTM [B,T,128] â†’ [B,T,128]
Block 1: sLSTM [B,T,128] â†’ [B,T,128]  â† çŸ­æœŸæ¨¡å¼
Block 2: mLSTM [B,T,128] â†’ [B,T,128]
Block 3: sLSTM [B,T,128] â†’ [B,T,128]  â† çŸ­æœŸæ¨¡å¼
Block 4: mLSTM [B,T,128] â†’ [B,T,128]
Block 5: mLSTM [B,T,128] â†’ [B,T,128]
```

**é—œéµæ–¹æ³•**:
```python
def get_hidden_states(self, x):
    embedded = self.input_embedding(x)    # [B,T,6] â†’ [B,T,128]
    embedded = self.dropout(embedded)
    xlstm_output = self.xlstm_stack(embedded)  # [B,T,128]
    return xlstm_output  # è¿”å›å®Œæ•´æ™‚åº
```

### 3. XLSTMSocialPoolingLayer - ç©ºé–“èšåˆ

**âš ï¸ é—œéµç™¼ç¾**: å¯¦éš›ä¸Šä¸ä½¿ç”¨å®Œæ•´çš„éš±è—ç‹€æ…‹åºåˆ—

**å¯¦éš›æ©Ÿåˆ¶**:
```python
# xlstm_pooling.py:124
neighbor_hidden = hidden_states[:, -1, :]  # åªå–æœ€å¾Œæ™‚é–“æ­¥ï¼

# ä¸‰ç¨®èšåˆæ–¹å¼
if pool_type == "mean":
    weight = 1.0 / neighbor_count
elif pool_type == "max":  
    # torch.max() æ“ä½œ
elif pool_type == "weighted_mean":
    weight = 1.0 / (distance + 1e-6)  # è·é›¢åæ¯”
```

**åƒæ•¸æƒ…æ³**:
```python
å¯å­¸ç¿’åƒæ•¸: 0 å€‹
learnable_radius: False  # å›ºå®šåŠå¾‘ 2000.0 ç±³
ç„¡æ¬Šé‡çŸ©é™£: ç´”æ•¸å­¸èšåˆ
ç„¡æ³¨æ„åŠ›æ©Ÿåˆ¶: åŸºæ–¼å¹¾ä½•è·é›¢
```

### 4. èåˆèˆ‡é æ¸¬å±¤

**èåˆæ©Ÿåˆ¶**:
```python
# distributed_social_xlstm.py:152-153
individual_hidden = individual_hidden_states[vd_id][:, -1, :]  # [B,128]
social_context = social_contexts[vd_id]                       # [B,128]
fused_features = torch.cat([individual_hidden, social_context], dim=-1)  # [B,256]
```

**é æ¸¬é ­**:
```python
self.prediction_head = nn.Sequential(
    nn.Linear(128, 64),           # 128 â†’ 64
    nn.ReLU(),
    nn.Dropout(0.1),
    nn.Linear(64, 18)             # 64 â†’ pred_lenÃ—features
)
```

## ğŸ“Š **æŠ€è¡“åƒæ•¸çµ±è¨ˆ**

### æ¨¡å‹è¦æ¨¡
```
ç¸½å¯è¨“ç·´åƒæ•¸: 42.3K (ç›¸å°è¼•é‡)
â”œâ”€â”€ TrafficXLSTMå¯¦ä¾‹: å‹•æ…‹å‰µå»º (æ¯å€‹VDç¨ç«‹)
â”œâ”€â”€ Social Pooling: 0å€‹åƒæ•¸
â”œâ”€â”€ Fusion Layer: 32.9Kåƒæ•¸ (77.8%)
â””â”€â”€ Prediction Head: 9.4Kåƒæ•¸ (22.2%)
```

### æ•¸æ“šæµè½‰æ›
```
è¼¸å…¥: Dict[325å€‹VDs, [B,T,F]] = Dict[325å€‹VDs, [16,12,6]]
xLSTM: Dict[325å€‹VDs, [16,12,128]] â†’ å–æœ€å¾Œæ­¥ â†’ Dict[325å€‹VDs, [16,128]]
Social: Dict[325å€‹VDs, [16,128]]  # ç©ºé–“èšåˆçµæœ
èåˆ: [16,128] âŠ• [16,128] â†’ [16,256] â†’ [16,128]
é æ¸¬: [16,128] â†’ [16,18]
è¼¸å‡º: Dict[325å€‹VDs, [16,18]]
```

## ğŸ¯ **æ ¸å¿ƒå‰µæ–°é»**

### 1. åˆ†æ•£å¼æ¶æ§‹
- **ç¨ç«‹å»ºæ¨¡**: æ¯å€‹ VD æœ‰å°ˆå±¬çš„ xLSTM å¯¦ä¾‹
- **å»¶é²åˆå§‹åŒ–**: è¨˜æ†¶é«”æ•ˆç‡å„ªåŒ–
- **å¯æ“´å±•æ€§**: æ”¯æŒå‹•æ…‹ VD å¢æ¸›

### 2. ç©ºé–“æ„ŸçŸ¥æ©Ÿåˆ¶  
- **é€£çºŒç©ºé–“**: åŸºæ–¼æ­å¹¾é‡Œå¾—è·é›¢ï¼Œéç¶²æ ¼åŒ–
- **åŠå¾‘ç´„æŸ**: 2000ç±³å…§é„°å±…åƒèˆ‡èšåˆ
- **ç„¡åƒæ•¸è¨­è¨ˆ**: ç´”å¹¾ä½•è¨ˆç®—ï¼Œé¿å…éæ“¬åˆ

### 3. æ··åˆæ™‚åºå»ºæ¨¡
- **sLSTM + mLSTM**: çŸ­æœŸéŸ¿æ‡‰èˆ‡é•·æœŸè¨˜æ†¶çµåˆ
- **çµ±ä¸€ç¶­åº¦**: embedding_dim=128 ä¿è­‰æ®˜å·®é€£æ¥
- **ä½ç½®ç­–ç•¥**: sLSTM åœ¨ [1,3] ä½ç½®è™•ç†çŸ­æœŸè®ŠåŒ–

## âš ï¸ **é‡è¦æŠ€è¡“æ¾„æ¸…**

### è¡“èªvså¯¦éš›
```
âŒ "Hidden Statesç¤¾äº¤æ± åŒ–"     â†’ âœ… "æœ€å¾Œæ™‚é–“æ­¥è¼¸å‡ºçš„ç©ºé–“èšåˆ"
âŒ "è¤‡é›œæ™‚åºç¤¾äº¤äº¤äº’"         â†’ âœ… "åŸºæ–¼æœ€å¾Œæ™‚é–“é»çš„é„°å±…èšåˆ"
âŒ "æ·±åº¦èåˆæ©Ÿåˆ¶"            â†’ âœ… "torch.cat() + å…©å±¤MLP"
âŒ "å¯å­¸ç¿’ç¤¾äº¤æ¬Šé‡"          â†’ âœ… "å›ºå®šè·é›¢å…¬å¼è¨ˆç®—æ¬Šé‡"
```

### å¯¦éš›æ•¸æ“šæµ
```python
# çœŸå¯¦çš„å‰å‘å‚³æ’­
individual_output = xlstm(input)[:, -1, :]      # åªç”¨æœ€å¾Œæ™‚é–“æ­¥
social_context = spatial_aggregate(neighbors)   # ç©ºé–“èšåˆé„°å±…
fused = torch.cat([individual, social])         # ç°¡å–®æ‹¼æ¥
prediction = mlp(fused)                         # å‰é¥‹ç¶²è·¯é æ¸¬
```

## ğŸ“ **è¨­è¨ˆç†å¿µ**

### YAGNI åŸå‰‡å¯¦è¸
- **é¿å…éåº¦è¨­è¨ˆ**: Social Pooling ç„¡åƒæ•¸ï¼Œç°¡å–®æœ‰æ•ˆ
- **åŠŸèƒ½åˆ†é›¢**: xLSTM è² è²¬æ™‚åºï¼Œç©ºé–“å±¤è² è²¬èšåˆï¼Œé æ¸¬é ­è² è²¬æ˜ å°„
- **è¨ˆç®—æ•ˆç‡**: å»¶é²åˆå§‹åŒ–ï¼Œåªç”¨æœ€å¾Œæ™‚é–“æ­¥

### äº¤é€šé æ¸¬é©æ‡‰æ€§
- **ç©ºé–“ç›¸é—œæ€§**: é„°è¿‘ VD ç‹€æ…‹å½±éŸ¿ç›®æ¨™ VD
- **æ™‚åºé€£çºŒæ€§**: xLSTM å»ºæ¨¡æ­·å²æ¨¡å¼
- **å¤šç‰¹å¾µå”åŒ**: åŒæ™‚é æ¸¬é€Ÿåº¦ã€æµé‡ç­‰å¤šå€‹ç‰¹å¾µ

## ğŸ”— **ç›¸é—œæ–‡ä»¶**

- æºä»£ç¢¼: `src/social_xlstm/models/distributed_social_xlstm.py`
- VDç®¡ç†å™¨: `src/social_xlstm/models/vd_xlstm_manager.py`
- ç¤¾äº¤æ± åŒ–: `src/social_xlstm/pooling/xlstm_pooling.py`
- é…ç½®ç³»çµ±: `src/social_xlstm/models/distributed_config.py`

---

**ä½œè€…**: Social-xLSTM Team  
**æœ€å¾Œæ›´æ–°**: 2025-01-26  
**ç‰ˆæœ¬**: v2.0 - åŸºæ–¼ä»£ç¢¼æ·±åº¦åˆ†æçš„çœŸå¯¦æ¶æ§‹æ–‡æª”

## ğŸ“‹ åŸå§‹ç›®éŒ„

1. [æ•´é«”æ¶æ§‹æ¦‚è¦½](#1-æ•´é«”æ¶æ§‹æ¦‚è¦½)
2. [VD xLSTM Manager](#2-vd-xlstm-manager)
3. [TrafficXLSTM æ ¸å¿ƒ](#3-trafficxlstm-æ ¸å¿ƒ)
4. [ç¤¾æœƒèšåˆå±¤](#4-ç¤¾æœƒèšåˆå±¤)
5. [å­å±¤ç´šç´°åˆ†çµæ§‹](#5-å­å±¤ç´šç´°åˆ†çµæ§‹)
6. [é…ç½®èˆ‡åƒæ•¸](#6-é…ç½®èˆ‡åƒæ•¸)
7. [æ€§èƒ½èˆ‡å„ªåŒ–](#7-æ€§èƒ½èˆ‡å„ªåŒ–)
8. [é™„éŒ„](#8-é™„éŒ„)

---

## ğŸ¯ æ–‡æª”æ¦‚è¦½

### ç›®æ¨™
æœ¬æ–‡æª”æä¾› Social-xLSTM æ¨¡å‹çš„å®Œæ•´æ¶æ§‹èªªæ˜ï¼Œæ¶µè“‹åˆ†æ•£å¼ VD ç®¡ç†ã€xLSTM æ ¸å¿ƒè™•ç†ã€ç¤¾æœƒèšåˆæ©Ÿåˆ¶çš„ç´°éƒ¨å¯¦ç¾ï¼Œä»¥åŠå®ƒå€‘ä¹‹é–“çš„æ•¸æ“šæµå‹•é—œä¿‚ã€‚

### è®€è€…å°è±¡
- å…·å‚™ PyTorch/æ·±åº¦å­¸ç¿’ç¶“é©—çš„å·¥ç¨‹äººå“¡
- äº¤é€šé æ¸¬èˆ‡æ™‚ç©ºå»ºæ¨¡é ˜åŸŸçš„ç ”ç©¶è€…
- éœ€è¦ç†è§£æˆ–æ“´å±• Social-xLSTM æ¶æ§‹çš„é–‹ç™¼è€…

### æ ¸å¿ƒå‰µæ–°
- **ç„¡æ‹“æ’²ä¾è³´**: åŸºæ–¼é€£çºŒè·é›¢çš„ç¤¾æœƒèšåˆï¼Œçªç ´å‚³çµ±ç¶²æ ¼é™åˆ¶
- **åˆ†æ•£å¼æ¶æ§‹**: æ¯å€‹ VD ç¨ç«‹ xLSTM å¯¦ä¾‹ï¼Œæ”¯æ´å‹•æ…‹æ“´å±•
- **æ··åˆè¨˜æ†¶**: sLSTM + mLSTM çµåˆï¼Œæå‡é•·çŸ­æœŸè¨˜æ†¶èƒ½åŠ›
- **å‹•æ…‹é…ç½®**: å››å±¤ YAML é…ç½®ç³»çµ±ï¼Œæ”¯æ´éˆæ´»çš„æ¶ˆèç ”ç©¶

### å¼µé‡ç¶­åº¦æ¨™æº–

æœ¬æ–‡æª”æ¡ç”¨ **BTNF æ¨™æº–**ï¼š
- **B**: Batch Size (æ‰¹æ¬¡å¤§å°)
- **T**: Time Steps (æ™‚é–“æ­¥é•·)
- **N**: Number of VDs (VD æ•¸é‡)
- **F**: Feature Dimension (ç‰¹å¾µç¶­åº¦)

---

## 1. æ•´é«”æ¶æ§‹æ¦‚è¦½

### 1.1 ç³»çµ±çµ„æˆ

Social-xLSTM æ¡ç”¨**åˆ†å±¤è§£è€¦**çš„è¨­è¨ˆç†å¿µï¼Œä¸»è¦ç”±å››å€‹æ ¸å¿ƒçµ„ä»¶æ§‹æˆï¼š

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  æ•¸æ“šè¼¸å…¥å±¤      â”‚â”€â”€â”€â–¶â”‚  VD xLSTM Manager â”‚â”€â”€â”€â–¶â”‚  ç¤¾æœƒèšåˆå±¤      â”‚â”€â”€â”€â–¶â”‚  é æ¸¬è¼¸å‡ºå±¤      â”‚
â”‚                â”‚    â”‚                  â”‚    â”‚                â”‚    â”‚                â”‚
â”‚ â€¢ äº¤é€šæµé‡æ•¸æ“š   â”‚    â”‚ â€¢ åˆ†æ•£å¼ç®¡ç†      â”‚    â”‚ â€¢ ç©ºé–“äº¤äº’å»ºæ¨¡   â”‚    â”‚ â€¢ å¤šæ­¥é æ¸¬      â”‚
â”‚ â€¢ åº§æ¨™ä¿¡æ¯      â”‚    â”‚ â€¢ æ‡¶åŠ è¼‰åˆå§‹åŒ–    â”‚    â”‚ â€¢ è·é›¢å‹èšåˆ     â”‚    â”‚ â€¢ æå¤±è¨ˆç®—      â”‚
â”‚ â€¢ VD æ˜ å°„      â”‚    â”‚ â€¢ æ¢¯åº¦æª¢æŸ¥é»      â”‚    â”‚ â€¢ å‹•æ…‹é„°å±…é¸æ“‡   â”‚    â”‚ â€¢ è©•ä¼°æŒ‡æ¨™      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                      â”‚  TrafficXLSTM    â”‚
                      â”‚                  â”‚
                      â”‚ â€¢ xLSTM Block    â”‚
                      â”‚ â€¢ sLSTM + mLSTM  â”‚
                      â”‚ â€¢ 654K åƒæ•¸      â”‚
                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.2 æ•¸æ“šæµæ¶æ§‹

#### ä¸»è¦æ•¸æ“šæµ
```python
# è¼¸å…¥éšæ®µ - Dict æ ¼å¼çš„ VD æ•¸æ“š
vd_inputs: Dict[str, torch.Tensor] = {
    "VD-28-0740-000-001": Tensor[B=4, T=12, F=3],  # [volume, speed, occupancy]
    "VD-11-0020-008-001": Tensor[B=4, T=12, F=3],
    "VD-13-0660-000-002": Tensor[B=4, T=12, F=3]
}

# è™•ç†éšæ®µ - æ¯å€‹ VD ç¨ç«‹è™•ç†
individual_hidden_states: Dict[str, torch.Tensor] = {
    "VD-28-0740-000-001": Tensor[B=4, T=12, H=128],  # xLSTM éš±ç‹€æ…‹
    "VD-11-0020-008-001": Tensor[B=4, T=12, H=128],
    "VD-13-0660-000-002": Tensor[B=4, T=12, H=128]
}

# ç¤¾æœƒèšåˆéšæ®µ - ç©ºé–“äº¤äº’å»ºæ¨¡
social_contexts: Dict[str, torch.Tensor] = {
    "VD-28-0740-000-001": Tensor[B=4, H=128],  # èšåˆçš„ç¤¾æœƒè„ˆçµ¡
    "VD-11-0020-008-001": Tensor[B=4, H=128],
    "VD-13-0660-000-002": Tensor[B=4, H=128]
}

# è¼¸å‡ºéšæ®µ - æœªä¾†é æ¸¬
predictions: Dict[str, torch.Tensor] = {
    "VD-28-0740-000-001": Tensor[B=4, P=1, F=3],  # é æ¸¬çµæœ
    "VD-11-0020-008-001": Tensor[B=4, P=1, F=3],
    "VD-13-0660-000-002": Tensor[B=4, P=1, F=3]
}
```

### 1.3 æ¶æ§‹ç‰¹é»

| ç‰¹æ€§ | èªªæ˜ | å„ªå‹¢ |
|------|------|------|
| **åˆ†æ•£å¼è¨­è¨ˆ** | æ¯å€‹ VD ç¨ç«‹ xLSTM å¯¦ä¾‹ | æ”¯æ´å‹•æ…‹ VD æ–°å¢/ç§»é™¤ |
| **æ‡¶åŠ è¼‰æ©Ÿåˆ¶** | æŒ‰éœ€åˆå§‹åŒ– VD æ¨¡å‹ | è¨˜æ†¶é«”æ•ˆç‡æœ€ä½³åŒ– |
| **ç„¡æ‹“æ’²ä¾è³´** | é€£çºŒè·é›¢èšåˆæ©Ÿåˆ¶ | ç„¡éœ€é å®šç¾©é“è·¯ç¶²è·¯ |
| **æ··åˆè¨˜æ†¶** | sLSTM + mLSTM æ¶æ§‹ | æå‡é•·çŸ­æœŸå»ºæ¨¡èƒ½åŠ› |
| **æ¨¡çµ„åŒ–è§£è€¦** | æ¸…æ™°çš„ä»‹é¢åˆ†é›¢ | ä¾¿æ–¼ç¶­è­·èˆ‡æ“´å±• |

### 1.4 ä»£ç¢¼å°æ‡‰

**ä¸»æ–‡ä»¶**: `src/social_xlstm/models/distributed_social_xlstm.py`

**æ ¸å¿ƒé¡åˆ¥**:
```python
class DistributedSocialXLSTMModel(pl.LightningModule):
    """ä¸»æ¶æ§‹é¡åˆ¥ï¼Œæ•´åˆæ‰€æœ‰çµ„ä»¶"""
    # è¡Œè™Ÿ: 40-306
    
    def forward(self, vd_inputs, neighbor_map=None, positions=None):
        """ä¸»è¦å‰å‘å‚³æ’­å‡½æ•¸"""
        # è¡Œè™Ÿ: 119-186
```

---

## 2. VD xLSTM Manager

### 2.1 çµ„ä»¶æ¦‚è¦½

VD xLSTM Manager (`VDXLSTMManager`) æ˜¯åˆ†æ•£å¼æ¶æ§‹çš„æ ¸å¿ƒç®¡ç†å™¨ï¼Œè² è²¬ç®¡ç†å¤šå€‹ VD å¯¦ä¾‹çš„ xLSTM æ¨¡å‹ï¼Œæä¾›çµ±ä¸€çš„ä»‹é¢å’Œé«˜æ•ˆçš„è³‡æºç®¡ç†ã€‚

**æª”æ¡ˆä½ç½®**: `src/social_xlstm/models/vd_xlstm_manager.py`

### 2.2 å±¤æ¬¡æ¶æ§‹

#### Layer 2.1: æ¨¡å‹å®¹å™¨å±¤ (Model Container Layer)
```python
class VDXLSTMManager(nn.Module):
    """åˆ†æ•£å¼ VD ç®¡ç†å™¨"""
    
    def __init__(self, xlstm_config, vd_ids=None, lazy_init=True):
        # ä½¿ç”¨ nn.ModuleDict è‡ªå‹•åƒæ•¸è¨»å†Š
        self.vd_models: nn.ModuleDict = nn.ModuleDict()
        self.initialized_vds: set = set()
```

**åŠŸèƒ½**:
- ä½¿ç”¨ `nn.ModuleDict` ç¢ºä¿æ‰€æœ‰ VD æ¨¡å‹åƒæ•¸æ­£ç¢ºè¨»å†Š
- æ”¯æ´å‹•æ…‹æ–°å¢/ç§»é™¤ VD å¯¦ä¾‹
- çµ±ä¸€çš„è¨­å‚™ç®¡ç†å’Œåƒæ•¸åŒæ­¥

#### Layer 2.2: æ‡¶åŠ è¼‰ç®¡ç†å±¤ (Lazy Initialization Layer)
```python
def _initialize_vd(self, vd_id: str) -> None:
    """æŒ‰éœ€åˆå§‹åŒ–å–®ä¸€ VD æ¨¡å‹"""
    if vd_id not in self.vd_models:
        self.vd_models[vd_id] = self._create_xlstm_model(vd_id)
        self.initialized_vds.add(vd_id)
```

**å„ªå‹¢**:
- è¨˜æ†¶é«”æ•ˆç‡ï¼šåƒ…åˆå§‹åŒ–å¯¦éš›ä½¿ç”¨çš„ VD
- æ”¯æ´å¤§è¦æ¨¡ VD éƒ¨ç½² (1000+ VDs)
- å‹•æ…‹æ“´å±•èƒ½åŠ›

#### Layer 2.3: æ¢¯åº¦æª¢æŸ¥é»å±¤ (Gradient Checkpointing Layer)
```python
def enable_gradient_checkpointing_all(self) -> None:
    """ç‚ºæ‰€æœ‰ VD æ¨¡å‹å•Ÿç”¨æ¢¯åº¦æª¢æŸ¥é»"""
    for vd_id, model in self.vd_models.items():
        if hasattr(model, 'gradient_checkpointing_enable'):
            model.gradient_checkpointing_enable()
```

**è¨˜æ†¶é«”ç¯€çœ**:
- å¯ç¯€çœç´„ 40-60% çš„è¨“ç·´è¨˜æ†¶é«”
- ä»£åƒ¹ï¼šå¢åŠ ç´„ 20-30% çš„è¨ˆç®—æ™‚é–“
- é©åˆå¤§æ¨¡å‹æˆ–æœ‰é™ GPU è¨˜æ†¶é«”å ´æ™¯

#### Layer 2.4: è¨­å‚™åŒæ­¥å±¤ (Device Synchronization Layer)
```python
def forward(self, batch_dict: Dict[str, torch.Tensor]) -> Dict[str, torch.Tensor]:
    """çµ±ä¸€çš„å‰å‘å‚³æ’­è™•ç†"""
    for vd_id, input_tensor in batch_dict.items():
        # ç¢ºä¿æ¨¡å‹èˆ‡è¼¸å…¥å¼µé‡åœ¨åŒä¸€è¨­å‚™
        if input_tensor.device != next(vd_model.parameters()).device:
            vd_model = vd_model.to(input_tensor.device)
```

### 2.3 API ä»‹é¢

#### ä¸»è¦æ–¹æ³•
```python
# åˆå§‹åŒ–
manager = VDXLSTMManager(
    xlstm_config=config,
    lazy_init=True,
    enable_gradient_checkpointing=True
)

# å‹•æ…‹ç®¡ç†
manager.add_vd("VD_NEW_001")
manager.remove_vd("VD_OLD_002")

# æ‰¹æ¬¡è™•ç†
hidden_states = manager(batch_dict)  # è¿”å›æ‰€æœ‰ VD çš„éš±ç‹€æ…‹

# è³‡æºç›£æ§
memory_info = manager.get_memory_usage()
```

#### è¼¸å…¥/è¼¸å‡ºæ ¼å¼
```python
# è¼¸å…¥
batch_dict: Dict[str, torch.Tensor]
# æ ¼å¼: {"VD_ID": Tensor[B, T, F]}

# è¼¸å‡º  
hidden_states: Dict[str, torch.Tensor]
# æ ¼å¼: {"VD_ID": Tensor[B, T, H]}  # H=128 (éš±ç‹€æ…‹ç¶­åº¦)
```

### 2.4 æ€§èƒ½ç‰¹æ€§

| æŒ‡æ¨™ | æ•¸å€¼ | å‚™è¨» |
|------|------|------|
| **æ”¯æ´ VD æ•¸** | 1000+ | ç†è«–ä¸Šé™å–æ±ºæ–¼ GPU è¨˜æ†¶é«” |
| **åˆå§‹åŒ–æ™‚é–“** | O(1) per VD | æ‡¶åŠ è¼‰æ©Ÿåˆ¶ |
| **è¨˜æ†¶é«”æ•ˆç‡** | 40-60% ç¯€çœ | æ¢¯åº¦æª¢æŸ¥é»å•Ÿç”¨æ™‚ |
| **å‹•æ…‹æ“´å±•** | æ¯«ç§’ç´š | æ–°å¢/ç§»é™¤ VD |

---

## 3. TrafficXLSTM æ ¸å¿ƒ

### 3.1 çµ„ä»¶æ¦‚è¦½

TrafficXLSTM æ˜¯äº¤é€šé æ¸¬çš„æ ¸å¿ƒåºåˆ—å»ºæ¨¡å™¨ï¼ŒåŸºæ–¼æ“´å±• LSTM (xLSTM) æ¶æ§‹ï¼Œçµåˆ sLSTM å’Œ mLSTM çš„æ··åˆè¨­è¨ˆã€‚

**æª”æ¡ˆä½ç½®**: `src/social_xlstm/models/xlstm.py`

### 3.2 xLSTM æ¶æ§‹è©³è§£

#### Layer 3.1: é…ç½®ç®¡ç†å±¤ (Configuration Layer)
```python
@dataclass
class TrafficXLSTMConfig:
    """TrafficXLSTM é…ç½®é¡åˆ¥"""
    input_size: int = 3              # [volume, speed, occupancy]
    embedding_dim: int = 128         # åµŒå…¥ç¶­åº¦
    hidden_size: int = 128           # éš±ç‹€æ…‹ç¶­åº¦
    num_blocks: int = 6              # xLSTM å€å¡Šæ•¸é‡
    slstm_at: List[int] = [1, 3]     # sLSTM ä½ç½®
    context_length: int = 256        # ä¸Šä¸‹æ–‡é•·åº¦
    dropout: float = 0.1             # Dropout æ¯”ç‡
```

**è¨­è¨ˆæ±ºç­–**:
- **6 å€‹å€å¡Š**: å¹³è¡¡æ¨¡å‹å®¹é‡èˆ‡è¨ˆç®—æ•ˆç‡
- **sLSTM ä½ç½® [1, 3]**: æ··åˆ sLSTM èˆ‡ mLSTM çš„æœ€ä½³é…ç½®
- **ä¸Šä¸‹æ–‡é•·åº¦ 256**: æ”¯æ´é•·åºåˆ—å»ºæ¨¡

#### Layer 3.2: è¼¸å…¥åµŒå…¥å±¤ (Input Embedding Layer)
```python
# è¼¸å…¥åµŒå…¥
self.input_embedding = nn.Linear(config.input_size, config.embedding_dim)

# è¼¸å…¥: [B, T, 3] -> è¼¸å‡º: [B, T, 128]
embedded = self.input_embedding(x)  # äº¤é€šç‰¹å¾µè½‰æ›ç‚ºåµŒå…¥ç©ºé–“
embedded = self.dropout(embedded)   # æ­£å‰‡åŒ–
```

**è™•ç†æµç¨‹**:
1. åŸå§‹äº¤é€šæ•¸æ“š `[volume, speed, occupancy]` â†’ åµŒå…¥ç©ºé–“
2. Dropout æ­£å‰‡åŒ–é˜²æ­¢éæ“¬åˆ
3. ç‚º xLSTM å †ç–Šæº–å‚™çµ±ä¸€ç¶­åº¦

#### Layer 3.3: xLSTM å€å¡Šå †ç–Šå±¤ (xLSTM Block Stack)
```python
# xLSTM é…ç½®
xlstm_config = xLSTMBlockStackConfig(
    mlstm_block=mlstm_config,        # mLSTM å€å¡Šé…ç½®
    slstm_block=slstm_config,        # sLSTM å€å¡Šé…ç½®
    num_blocks=6,                    # ç¸½å€å¡Šæ•¸
    slstm_at=[1, 3],                # sLSTM ä½ç½®
    embedding_dim=128                # åµŒå…¥ç¶­åº¦
)

# xLSTM å †ç–Š
self.xlstm_stack = xLSTMBlockStack(xlstm_config)
```

**å€å¡Šé…ç½®**:
```
Block 0: mLSTM  â†â”€â”€ è¨˜æ†¶å®¹é‡æ“´å±•
Block 1: sLSTM  â†â”€â”€ é¸æ“‡æ€§è¨˜æ†¶
Block 2: mLSTM  â†â”€â”€ è¨˜æ†¶å®¹é‡æ“´å±•
Block 3: sLSTM  â†â”€â”€ é¸æ“‡æ€§è¨˜æ†¶
Block 4: mLSTM  â†â”€â”€ è¨˜æ†¶å®¹é‡æ“´å±•
Block 5: mLSTM  â†â”€â”€ è¨˜æ†¶å®¹é‡æ“´å±•
```

#### Layer 3.4: å¤šç¶­åº¦è¼¸å…¥è™•ç†å±¤ (Multi-dimensional Input Handler)
```python
def forward(self, x: torch.Tensor) -> torch.Tensor:
    """æ”¯æ´å–®VDå’Œå¤šVDæ¨¡å¼çš„å‰å‘å‚³æ’­"""
    
    if self.config.multi_vd_mode:
        # 4D è¼¸å…¥è™•ç†: [B, T, N, F]
        if x.dim() == 4:
            seq_len, num_vds, num_features = x.size(1), x.size(2), x.size(3)
            x = x.view(batch_size, seq_len, num_vds * num_features)
            
        # 3D è¼¸å…¥è™•ç†: [B, T, flattened_features] (é å±•å¹³)
        elif x.dim() == 3:
            seq_len, flattened_features = x.size(1), x.size(2)
    else:
        # å–®VDæ¨¡å¼: [B, T, F]
        if x.dim() != 3:
            raise ValueError(f"å–®VDæ¨¡å¼æœŸæœ›3Dè¼¸å…¥ï¼Œå¾—åˆ°{x.dim()}D")
```

#### Layer 3.5: åºåˆ—è™•ç†èˆ‡è¼¸å‡ºå±¤ (Sequence Processing & Output Layer)
```python
# xLSTM åºåˆ—è™•ç†
xlstm_output = self.xlstm_stack(embedded)  # [B, T, 128]

# å–æœ€å¾Œæ™‚é–“æ­¥ç”¨æ–¼é æ¸¬
last_hidden = xlstm_output[:, -1, :]      # [B, 128]

# è¼¸å‡ºæŠ•å½±
output = self.output_projection(last_hidden)  # [B, 3]

# é‡å¡‘ç‚ºé æœŸæ ¼å¼
output = output.unsqueeze(1)              # [B, 1, 3]
```

### 3.3 éš±ç‹€æ…‹æå–ä»‹é¢

```python
def get_hidden_states(self, x: torch.Tensor) -> torch.Tensor:
    """æå– xLSTM éš±ç‹€æ…‹ä¾›ç¤¾æœƒèšåˆä½¿ç”¨"""
    embedded = self.input_embedding(x)
    embedded = self.dropout(embedded)
    xlstm_output = self.xlstm_stack(embedded)  # [B, T, 128]
    return xlstm_output
```

**ç”¨é€”**: ç‚ºç¤¾æœƒèšåˆå±¤æä¾›æ™‚åºéš±ç‹€æ…‹ï¼Œæ”¯æ´ç©ºé–“äº¤äº’å»ºæ¨¡ã€‚

### 3.4 æ¨¡å‹è¦æ¨¡åˆ†æ

| çµ„ä»¶ | åƒæ•¸é‡ | æ¯”ä¾‹ |
|------|--------|------|
| **è¼¸å…¥åµŒå…¥** | 384 | 0.1% |
| **xLSTM å †ç–Š** | 653,248 | 99.7% |
| **è¼¸å‡ºæŠ•å½±** | 387 | 0.1% |
| **ç¸½è¨ˆ** | **654,883** | **100%** |

**è¨˜æ†¶é«”ä½¿ç”¨**:
- **æ¨è«–**: ~2.6 MB (fp32) / ~1.3 MB (fp16)
- **è¨“ç·´**: ~10-15 MB (å«æ¢¯åº¦å’Œå„ªåŒ–å™¨ç‹€æ…‹)

---

## 4. ç¤¾æœƒèšåˆå±¤

### 4.1 çµ„ä»¶æ¦‚è¦½

ç¤¾æœƒèšåˆå±¤ (Social Pooling Layer) å¯¦ç¾**ç„¡æ‹“æ’²ä¾è³´**çš„ç©ºé–“äº¤äº’å»ºæ¨¡ï¼Œä½¿ç”¨é€£çºŒè·é›¢æ©Ÿåˆ¶å–ä»£å‚³çµ±ç¶²æ ¼é›¢æ•£åŒ–æ–¹æ³•ã€‚

**æª”æ¡ˆä½ç½®**: `src/social_xlstm/pooling/xlstm_pooling.py`

### 4.2 æ ¸å¿ƒç®—æ³•

#### Layer 4.1: è·é›¢è¨ˆç®—å±¤ (Distance Computation Layer)
```python
def xlstm_hidden_states_aggregation(
    agent_hidden_states: Dict[str, torch.Tensor],
    agent_positions: Dict[str, torch.Tensor], 
    target_agent_id: str,
    radius: float = 2.0,
    pool_type: str = "mean"
) -> torch.Tensor:
    """æ ¸å¿ƒèšåˆç®—æ³•"""
    
    # è¨ˆç®—æ­å¹¾é‡Œå¾—è·é›¢
    distance = torch.norm(target_pos_last - neighbor_pos, p=2, dim=-1)  # [B]
    
    # é„°å±…é¸æ“‡
    within_radius = distance <= radius  # [B]
```

**è·é›¢æ©Ÿåˆ¶**:
- **æ­å¹¾é‡Œå¾—è·é›¢**: `||pos_i - pos_j||_2`
- **åŠå¾‘é¸æ“‡**: 2.0 å…¬å°ºé è¨­åŠå¾‘
- **å‹•æ…‹é„°å±…**: æ¯æ‰¹æ¬¡å‹•æ…‹è¨ˆç®—é„°å±…é—œä¿‚

#### Layer 4.2: èšåˆç­–ç•¥å±¤ (Aggregation Strategy Layer)

##### A. å¹³å‡èšåˆ (Mean Pooling)
```python
if pool_type == "mean":
    neighbor_mask = torch.any(stacked_neighbors != 0, dim=-1)  # [num_neighbors, B]
    neighbor_count = neighbor_mask.sum(dim=0).float()         # [B]
    neighbor_count = torch.clamp(neighbor_count, min=1.0)
    social_context = stacked_neighbors.sum(dim=0) / neighbor_count.unsqueeze(-1)
```

##### B. åŠ æ¬Šå¹³å‡èšåˆ (Weighted Mean Pooling)
```python
elif pool_type == "weighted_mean":
    # é€†è·é›¢æ¬Šé‡
    weights = 1.0 / (distance + 1e-6)  # [B]
    weights = torch.where(within_radius, weights, torch.zeros_like(weights))
    
    # æ­¸ä¸€åŒ–æ¬Šé‡
    normalized_weights = stacked_weights / total_weights
    
    # åŠ æ¬Šèšåˆ
    weighted_neighbors = stacked_neighbors * normalized_weights.unsqueeze(-1)
    social_context = weighted_neighbors.sum(dim=0)
```

##### C. æ³¨æ„åŠ›èšåˆ (Attention Pooling)
```python
elif pool_type == "attention":
    # è¨ˆç®—æ³¨æ„åŠ›åˆ†æ•¸
    attention_scores = self.attention_layer(
        query=target_hidden_state,
        key=neighbor_hidden_states,
        value=neighbor_hidden_states
    )
    
    # Softmax æ­¸ä¸€åŒ–
    attention_weights = torch.softmax(attention_scores, dim=1)
    
    # æ³¨æ„åŠ›åŠ æ¬Šèšåˆ
    social_context = torch.sum(attention_weights * neighbor_hidden_states, dim=1)
```

#### Layer 4.3: ç¥ç¶“ç¶²è·¯åŒ…è£å±¤ (Neural Network Wrapper Layer)
```python
class XLSTMSocialPoolingLayer(nn.Module):
    """PyTorch nn.Module åŒ…è£å™¨"""
    
    def __init__(self, hidden_dim, radius=2.0, pool_type="mean", learnable_radius=False):
        super().__init__()
        self.hidden_dim = hidden_dim
        self.pool_type = pool_type
        
        if learnable_radius:
            self.radius = nn.Parameter(torch.tensor(radius))  # å¯å­¸ç¿’åŠå¾‘
        else:
            self.register_buffer('radius', torch.tensor(radius))  # å›ºå®šåŠå¾‘
    
    def forward(self, agent_hidden_states, agent_positions, target_agent_ids=None):
        """æ‰¹æ¬¡ç¤¾æœƒèšåˆè™•ç†"""
        social_contexts = OrderedDict()
        
        for target_id in target_agent_ids:
            social_context = xlstm_hidden_states_aggregation(
                agent_hidden_states, agent_positions, target_id,
                float(self.radius), self.pool_type
            )
            social_contexts[target_id] = social_context
            
        return social_contexts
```

### 4.3 èšåˆç­–ç•¥æ¯”è¼ƒ

| ç­–ç•¥ | è¨ˆç®—è¤‡é›œåº¦ | è¨˜æ†¶é«”ä½¿ç”¨ | è¡¨é”èƒ½åŠ› | é©ç”¨å ´æ™¯ |
|------|------------|------------|----------|----------|
| **Mean** | O(NK) | ä½ | åŸºç¤ | å¿«é€ŸåŸå‹ |
| **Weighted Mean** | O(NK) | ä½ | ä¸­ç­‰ | ä¸€èˆ¬ä½¿ç”¨ |
| **Max** | O(NK) | ä½ | ä¸­ç­‰ | ç‰¹å¾µçªå‡º |
| **Attention** | O(NKÂ²) | é«˜ | é«˜ | è¤‡é›œäº¤äº’ |

### 4.4 èˆ‡å‚³çµ±æ–¹æ³•å°æ¯”

#### å‚³çµ± Social LSTM (ç¶²æ ¼æ–¹æ³•)
```python
# ç¶²æ ¼é›¢æ•£åŒ–
H^i_t(m,n,:) = Î£_{jâˆˆN_i} 1_{mn}[x^j_t - x^i_t, y^j_t - y^i_t] h^j_{t-1}
```

#### Social-xLSTM (è·é›¢æ–¹æ³•)  
```python
# é€£çºŒè·é›¢èšåˆ
distance = ||pos_i - pos_j||_2
neighbors = {j : distance â‰¤ radius}
social_context = weighted_mean(neighbor_hidden_states)
```

**å„ªå‹¢**:
- âœ… ç„¡é›¢æ•£åŒ–èª¤å·®
- âœ… è¨ˆç®—æ•ˆç‡æ›´é«˜ 
- âœ… æ›´é©åˆç¨€ç–äº¤é€šå ´æ™¯
- âœ… å¯å¾®åˆ†æ¬Šé‡æ©Ÿåˆ¶

---

## 5. å­å±¤ç´šç´°åˆ†çµæ§‹

### 5.1 åˆ†æ•£å¼æ¶æ§‹å­å±¤

#### 5.1.1 åˆå§‹åŒ–ç®¡ç†å­å±¤
```python
# VDXLSTMManager å…§éƒ¨
class InitializationManager:
    """VD åˆå§‹åŒ–ç®¡ç†å­ç³»çµ±"""
    
    def lazy_initialize(self, vd_id: str):
        """æ‡¶åŠ è¼‰åˆå§‹åŒ–"""
        if vd_id not in self.vd_models:
            model = TrafficXLSTM(self.xlstm_config)
            self.vd_models[vd_id] = model
            self.initialized_vds.add(vd_id)
```

#### 5.1.2 è¨­å‚™åŒæ­¥å­å±¤
```python
class DeviceSynchronizer:
    """è¨­å‚™åŒæ­¥ç®¡ç†"""
    
    def sync_device(self, model, target_device):
        """ç¢ºä¿æ¨¡å‹èˆ‡è¼¸å…¥åœ¨åŒä¸€è¨­å‚™"""
        if next(model.parameters()).device != target_device:
            model = model.to(target_device)
```

### 5.2 xLSTM å…§éƒ¨å­å±¤

#### 5.2.1 åµŒå…¥è®Šæ›å­å±¤
```python
class InputEmbedding(nn.Module):
    """è¼¸å…¥åµŒå…¥å­å±¤"""
    def __init__(self, input_size=3, embedding_dim=128):
        super().__init__()
        self.linear = nn.Linear(input_size, embedding_dim)
        self.dropout = nn.Dropout(0.1)
    
    def forward(self, x):
        return self.dropout(self.linear(x))
```

#### 5.2.2 xLSTM å€å¡Šå­å±¤
```python
# xlstm åº«æä¾›çš„å€å¡Š
class xLSTMBlockStack:
    """xLSTM å€å¡Šå †ç–Š"""
    # Block 0: mLSTMBlock
    # Block 1: sLSTMBlock  â† é¸æ“‡æ€§è¨˜æ†¶
    # Block 2: mLSTMBlock
    # Block 3: sLSTMBlock  â† é¸æ“‡æ€§è¨˜æ†¶
    # Block 4: mLSTMBlock
    # Block 5: mLSTMBlock
```

#### 5.2.3 è¼¸å‡ºæŠ•å½±å­å±¤
```python
class OutputProjection(nn.Module):
    """è¼¸å‡ºæŠ•å½±å­å±¤"""
    def __init__(self, embedding_dim=128, output_size=3):
        super().__init__()
        self.linear = nn.Linear(embedding_dim, output_size)
    
    def forward(self, x):
        return self.linear(x)
```

### 5.3 ç¤¾æœƒèšåˆå…§éƒ¨å­å±¤

#### 5.3.1 è·é›¢è¨ˆç®—å­å±¤
```python
class DistanceComputer:
    """è·é›¢è¨ˆç®—å­ç³»çµ±"""
    
    @staticmethod
    def euclidean_distance(pos_a, pos_b):
        """è¨ˆç®—æ­å¹¾é‡Œå¾—è·é›¢"""
        return torch.norm(pos_a - pos_b, p=2, dim=-1)
    
    @staticmethod
    def select_neighbors(distance, radius):
        """é¸æ“‡åŠå¾‘å…§é„°å±…"""
        return distance <= radius
```

#### 5.3.2 æ¬Šé‡è¨ˆç®—å­å±¤
```python
class WeightCalculator:
    """æ¬Šé‡è¨ˆç®—å­ç³»çµ±"""
    
    @staticmethod
    def inverse_distance_weight(distance, epsilon=1e-6):
        """é€†è·é›¢æ¬Šé‡"""
        return 1.0 / (distance + epsilon)
    
    @staticmethod
    def gaussian_weight(distance, sigma=1.0):
        """é«˜æ–¯æ¬Šé‡"""
        return torch.exp(-distance**2 / (2 * sigma**2))
```

#### 5.3.3 èšåˆåŸ·è¡Œå­å±¤
```python
class AggregationExecutor:
    """èšåˆåŸ·è¡Œå­ç³»çµ±"""
    
    def mean_aggregation(self, neighbor_states):
        """å¹³å‡èšåˆ"""
        return torch.mean(neighbor_states, dim=0)
    
    def weighted_aggregation(self, neighbor_states, weights):
        """åŠ æ¬Šèšåˆ"""
        normalized_weights = weights / torch.sum(weights)
        return torch.sum(neighbor_states * normalized_weights.unsqueeze(-1), dim=0)
```

### 5.4 èåˆèˆ‡é æ¸¬å­å±¤

#### 5.4.1 ç‰¹å¾µèåˆå­å±¤
```python
class FeatureFusion(nn.Module):
    """ç‰¹å¾µèåˆå­å±¤ - distributed_social_xlstm.py:96-100"""
    
    def __init__(self, hidden_dim=128):
        super().__init__()
        self.fusion_layer = nn.Sequential(
            nn.Linear(hidden_dim * 2, hidden_dim),  # [å€‹é«”, ç¤¾æœƒ] â†’ èåˆ
            nn.ReLU(),
            nn.Dropout(0.1)
        )
    
    def forward(self, individual_hidden, social_context):
        """èåˆå€‹é«”ç‰¹å¾µèˆ‡ç¤¾æœƒè„ˆçµ¡"""
        fused_features = torch.cat([individual_hidden, social_context], dim=-1)
        return self.fusion_layer(fused_features)
```

#### 5.4.2 é æ¸¬é ­å­å±¤
```python
class PredictionHead(nn.Module):
    """é æ¸¬é ­å­å±¤ - distributed_social_xlstm.py:103-108"""
    
    def __init__(self, hidden_dim=128, prediction_length=1, num_features=3):
        super().__init__()
        self.prediction_head = nn.Sequential(
            nn.Linear(hidden_dim, hidden_dim // 2),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(hidden_dim // 2, prediction_length * num_features)
        )
    
    def forward(self, fused_features):
        """ç”Ÿæˆæœ€çµ‚é æ¸¬"""
        prediction = self.prediction_head(fused_features)
        return prediction
```

### 5.5 è¨“ç·´èˆ‡è©•ä¼°å­å±¤

#### 5.5.1 æå¤±è¨ˆç®—å­å±¤
```python
class LossCalculator:
    """æå¤±è¨ˆç®—å­ç³»çµ±"""
    
    def __init__(self):
        self.criterion = nn.MSELoss()
    
    def compute_vd_loss(self, predictions, targets):
        """è¨ˆç®—å–®å€‹VDçš„æå¤±"""
        total_loss = 0.0
        num_vds = 0
        
        for vd_id, pred in predictions.items():
            if vd_id in targets:
                target = targets[vd_id]
                target_flat = target.reshape(target.shape[0], -1)
                vd_loss = self.criterion(pred, target_flat)
                total_loss += vd_loss
                num_vds += 1
        
        return total_loss / num_vds if num_vds > 0 else total_loss
```

#### 5.5.2 è©•ä¼°æŒ‡æ¨™å­å±¤
```python
class MetricsCalculator:
    """è©•ä¼°æŒ‡æ¨™è¨ˆç®—å­ç³»çµ±"""
    
    def __init__(self):
        self.mae = torchmetrics.MeanAbsoluteError()
        self.mse = torchmetrics.MeanSquaredError()
        self.rmse = torchmetrics.MeanSquaredError(squared=False)
        self.r2 = torchmetrics.R2Score()
    
    def update_metrics(self, predictions, targets):
        """æ›´æ–°æ‰€æœ‰è©•ä¼°æŒ‡æ¨™"""
        self.mae(predictions, targets)
        self.mse(predictions, targets) 
        self.rmse(predictions, targets)
        self.r2(predictions, targets)
```

---

## 6. é…ç½®èˆ‡åƒæ•¸

### 6.1 å››å±¤é…ç½®æ¶æ§‹

Social-xLSTM æ¡ç”¨**å››å±¤ YAML é…ç½®ç³»çµ±**ï¼Œæ”¯æ´éˆæ´»çš„æ¶ˆèç ”ç©¶ï¼š

```bash
cfgs/
â”œâ”€â”€ models/           # Layer 1: æ¨¡å‹æ¶æ§‹é…ç½®
â”‚   â”œâ”€â”€ lstm.yaml     # å‚³çµ± LSTM åŸºæº–
â”‚   â””â”€â”€ xlstm.yaml    # xLSTM æ ¸å¿ƒé…ç½®
â”œâ”€â”€ social_pooling/   # Layer 2: ç¤¾æœƒèšåˆé…ç½®  
â”‚   â”œâ”€â”€ off.yaml      # ç„¡èšåˆåŸºæº–
â”‚   â”œâ”€â”€ weighted_mean.yaml
â”‚   â”œâ”€â”€ weighted_sum.yaml
â”‚   â””â”€â”€ attention.yaml
â”œâ”€â”€ vd_modes/         # Layer 3: VD æ¨¡å¼é…ç½®
â”‚   â”œâ”€â”€ single.yaml   # å–®é»é æ¸¬
â”‚   â””â”€â”€ multi.yaml    # å¤šé»é æ¸¬
â””â”€â”€ training/         # Layer 4: è¨“ç·´è¶…åƒæ•¸
    â””â”€â”€ default.yaml
```

### 6.2 é…ç½®ç¯„ä¾‹

#### 6.2.1 æ¨¡å‹é…ç½® (xlstm.yaml)
```yaml
model:
  name: "TrafficXLSTM"
  xlstm:
    input_size: 3                    # [volume, speed, occupancy]
    embedding_dim: 128               # åµŒå…¥ç¶­åº¦
    hidden_size: 128                 # éš±ç‹€æ…‹ç¶­åº¦
    num_blocks: 6                    # xLSTM å€å¡Šæ•¸
    slstm_at: [1, 3]                # sLSTM ä½ç½®
    slstm_backend: "vanilla"         # sLSTM å¾Œç«¯
    mlstm_backend: "vanilla"         # mLSTM å¾Œç«¯
    context_length: 256              # ä¸Šä¸‹æ–‡é•·åº¦
    dropout: 0.1                     # Dropout æ¯”ç‡
    batch_first: true                # æ‰¹æ¬¡å„ªå…ˆæ ¼å¼
```

#### 6.2.2 ç¤¾æœƒèšåˆé…ç½® (attention.yaml)
```yaml
social:
  enabled: true                      # å•Ÿç”¨ç¤¾æœƒèšåˆ
  pooling_radius: 2500.0            # èšåˆåŠå¾‘ (å…¬å°º)
  max_neighbors: 10                 # æœ€å¤§é„°å±…æ•¸
  aggregation_method: "attention"   # èšåˆæ–¹æ³•
  distance_metric: "euclidean"      # è·é›¢åº¦é‡
  learnable_radius: false           # å¯å­¸ç¿’åŠå¾‘
  attention:
    num_heads: 4                    # æ³¨æ„åŠ›é ­æ•¸
    dropout: 0.1                    # æ³¨æ„åŠ› Dropout
```

#### 6.2.3 VD æ¨¡å¼é…ç½® (multi.yaml)
```yaml
vd_mode:
  type: "multi_vd"                  # å¤šVDæ¨¡å¼
  max_vds: 50                       # æœ€å¤§VDæ•¸é‡
  sequence_length: 12               # è¼¸å…¥åºåˆ—é•·åº¦
  prediction_length: 3              # é æ¸¬é•·åº¦
  features:
    - "volume"                      # æµé‡
    - "speed"                       # é€Ÿåº¦  
    - "occupancy"                   # å æœ‰ç‡
```

#### 6.2.4 è¨“ç·´é…ç½® (default.yaml)
```yaml
training:
  epochs: 50                        # è¨“ç·´è¼ªæ•¸
  batch_size: 16                    # æ‰¹æ¬¡å¤§å°
  learning_rate: 1e-3               # å­¸ç¿’ç‡
  optimizer: "adam"                 # å„ªåŒ–å™¨
  scheduler:
    type: "reduce_lr_on_plateau"    # å­¸ç¿’ç‡èª¿åº¦å™¨
    factor: 0.5                     # è¡°æ¸›å› å­
    patience: 10                    # è€å¿ƒç­‰å¾…è¼ªæ•¸
  early_stopping:
    patience: 15                    # æ—©åœè€å¿ƒ
    min_delta: 1e-4                # æœ€å°æ”¹å–„
  gradient_clipping:
    max_norm: 1.0                   # æ¢¯åº¦è£å‰ª
```

### 6.3 å‹•æ…‹é…ç½®åˆä½µ

ä½¿ç”¨ `snakemake_warp.py` å¯¦ç¾é…ç½®å‹•æ…‹åˆä½µï¼š

```bash
# Attention-based ç¤¾æœƒèšåˆ
python workflow/snakemake_warp.py \
  --configfile cfgs/models/xlstm.yaml \
  --configfile cfgs/social_pooling/attention.yaml \
  --configfile cfgs/vd_modes/multi.yaml \
  --configfile cfgs/training/default.yaml \
  train_social_xlstm_multi_vd --cores 2
```

**é…ç½®åˆä½µè¦å‰‡**:
1. **å­—å…¸åˆä½µ**: æ·±åº¦éæ­¸åˆä½µ
2. **åˆ—è¡¨æ›¿æ›**: å¾Œä¾†é…ç½®å®Œå…¨æ›¿æ›
3. **å„ªå…ˆç´š**: å³åˆ°å·¦ï¼ˆå¾Œä¾†å±…ä¸Šï¼‰

### 6.4 åƒæ•¸èª¿å„ªæŒ‡å—

#### 6.4.1 æ¨¡å‹åƒæ•¸èª¿å„ª
| åƒæ•¸ | é è¨­å€¼ | èª¿å„ªç¯„åœ | å½±éŸ¿ |
|------|--------|----------|------|
| `embedding_dim` | 128 | [64, 256] | æ¨¡å‹å®¹é‡ |
| `num_blocks` | 6 | [4, 12] | æ¨¡å‹æ·±åº¦ |
| `dropout` | 0.1 | [0.05, 0.3] | æ­£å‰‡åŒ–å¼·åº¦ |
| `context_length` | 256 | [128, 512] | é•·ç¨‹ä¾è³´ |

#### 6.4.2 ç¤¾æœƒèšåˆåƒæ•¸èª¿å„ª
| åƒæ•¸ | é è¨­å€¼ | èª¿å„ªç¯„åœ | å½±éŸ¿ |
|------|--------|----------|------|
| `pooling_radius` | 2500.0 | [1000, 5000] | ç©ºé–“ç¯„åœ |
| `max_neighbors` | 10 | [5, 20] | è¨ˆç®—æ•ˆç‡ |
| `aggregation_method` | "attention" | [mean, weighted_mean, attention] | èšåˆå“è³ª |

#### 6.4.3 è¨“ç·´åƒæ•¸èª¿å„ª
| åƒæ•¸ | é è¨­å€¼ | èª¿å„ªç¯„åœ | å½±éŸ¿ |
|------|--------|----------|------|
| `learning_rate` | 1e-3 | [1e-4, 1e-2] | æ”¶æ–‚é€Ÿåº¦ |
| `batch_size` | 16 | [8, 64] | è¨“ç·´ç©©å®šæ€§ |
| `scheduler.patience` | 10 | [5, 20] | å­¸ç¿’ç‡èª¿æ•´ |

---

## 7. æ€§èƒ½èˆ‡å„ªåŒ–

### 7.1 æ¨¡å‹è¦æ¨¡åˆ†æ

#### 7.1.1 åƒæ•¸é‡çµ±è¨ˆ

| æ¨¡å‹è®Šé«” | ç¸½åƒæ•¸é‡ | è¨“ç·´åƒæ•¸ | è¨˜æ†¶é«”ä½¿ç”¨ (fp32) |
|----------|----------|----------|-------------------|
| **TrafficLSTM (å–®VD)** | 226,309 | 226,309 | ~0.9 MB |
| **TrafficXLSTM (å–®VD)** | 654,883 | 654,883 | ~2.6 MB |
| **Multi-VD LSTM** | 1,433,537 | 1,433,537 | ~5.7 MB |
| **Social-xLSTM** | 1,400,000+ | 1,400,000+ | ~5.6 MB |

#### 7.1.2 è¨ˆç®—è¤‡é›œåº¦

**æ™‚é–“è¤‡é›œåº¦**:
- **å–®VDè™•ç†**: O(T Ã— HÂ²) per VD
- **ç¤¾æœƒèšåˆ**: O(N Ã— K) per batch
- **ç¸½é«”**: O(N Ã— T Ã— HÂ² + N Ã— K)

**ç©ºé–“è¤‡é›œåº¦**:
- **éš±ç‹€æ…‹**: O(B Ã— T Ã— N Ã— H)
- **ç¤¾æœƒè„ˆçµ¡**: O(B Ã— N Ã— H)
- **æ¢¯åº¦**: èˆ‡åƒæ•¸é‡æˆæ­£æ¯”

### 7.2 è¨˜æ†¶é«”å„ªåŒ–ç­–ç•¥

#### 7.2.1 æ¢¯åº¦æª¢æŸ¥é» (Gradient Checkpointing)
```python
# å•Ÿç”¨æ¢¯åº¦æª¢æŸ¥é»
manager = VDXLSTMManager(
    xlstm_config=config,
    enable_gradient_checkpointing=True  # ç¯€çœ 40-60% è¨˜æ†¶é«”
)
```

**æ•ˆæœ**:
- âœ… è¨˜æ†¶é«”ç¯€çœ: 40-60%
- âŒ è¨ˆç®—å¢åŠ : 20-30%
- ğŸ“Š é©ç”¨: å¤§æ‰¹æ¬¡æˆ–æœ‰é™GPUè¨˜æ†¶é«”

#### 7.2.2 æ‡¶åŠ è¼‰æ©Ÿåˆ¶ (Lazy Initialization)
```python
# æ‡¶åŠ è¼‰VDå¯¦ä¾‹
manager = VDXLSTMManager(
    xlstm_config=config,
    lazy_init=True  # æŒ‰éœ€åˆå§‹åŒ–
)
```

**å„ªå‹¢**:
- åƒ…åˆå§‹åŒ–å¯¦éš›ä½¿ç”¨çš„VD
- æ”¯æ´1000+ VDè¦æ¨¡éƒ¨ç½²
- å‹•æ…‹æ“´å±•èƒ½åŠ›

#### 7.2.3 æ··åˆç²¾åº¦è¨“ç·´ (Mixed Precision)
```python
# PyTorch Lightning è‡ªå‹•æ··åˆç²¾åº¦
trainer = pl.Trainer(
    precision=16,           # fp16 è¨“ç·´
    amp_backend='native'    # ä½¿ç”¨åŸç”ŸAMP
)
```

**æ•ˆç›Š**:
- è¨˜æ†¶é«”ç¯€çœ: ~50%
- è¨“ç·´åŠ é€Ÿ: 1.5-2x
- æ•¸å€¼ç©©å®šæ€§: éœ€è¦é©ç•¶çš„æå¤±ç¸®æ”¾

### 7.3 è¨ˆç®—å„ªåŒ–ç­–ç•¥

#### 7.3.1 ç¤¾æœƒèšåˆå„ªåŒ–
```python
# é™åˆ¶é„°å±…æ•¸é‡
social_pooling = XLSTMSocialPoolingLayer(
    radius=2.0,
    max_neighbors=10  # é™åˆ¶è¨ˆç®—è¤‡é›œåº¦
)

# æ‰¹æ¬¡èšåˆ
def batch_social_pooling(hidden_states, positions, batch_size=32):
    """æ‰¹æ¬¡è™•ç†ç¤¾æœƒèšåˆä»¥æ§åˆ¶è¨˜æ†¶é«”"""
    results = []
    for i in range(0, len(hidden_states), batch_size):
        batch_results = social_pooling(
            hidden_states[i:i+batch_size],
            positions[i:i+batch_size]
        )
        results.append(batch_results)
    return torch.cat(results, dim=0)
```

#### 7.3.2 åºåˆ—é•·åº¦å„ªåŒ–
```python
# å‹•æ…‹åºåˆ—é•·åº¦
def dynamic_sequence_length(sequences, max_length=12):
    """æ ¹æ“šå¯¦éš›å…§å®¹èª¿æ•´åºåˆ—é•·åº¦"""
    actual_lengths = []
    for seq in sequences:
        # è¨ˆç®—å¯¦éš›æœ‰æ•ˆé•·åº¦
        non_zero_mask = torch.any(seq != 0, dim=-1)
        actual_length = torch.sum(non_zero_mask).item()
        actual_lengths.append(min(actual_length, max_length))
    
    return actual_lengths
```

### 7.4 åˆ†æ•£å¼è¨“ç·´å„ªåŒ–

#### 7.4.1 æ•¸æ“šä¸¦è¡Œ (Data Parallel)
```python
# PyTorch Lightning DDP
trainer = pl.Trainer(
    accelerator="gpu",
    devices=4,                    # 4 GPU
    strategy="ddp",               # åˆ†æ•£å¼æ•¸æ“šä¸¦è¡Œ
    sync_batchnorm=True,          # åŒæ­¥ BatchNorm
    gradient_clip_val=1.0         # æ¢¯åº¦è£å‰ª
)
```

#### 7.4.2 æ¨¡å‹ä¸¦è¡Œ (Model Parallel)
```python
# å¤§è¦æ¨¡VDéƒ¨ç½²çš„æ¨¡å‹åˆ†ç‰‡
class ShardedVDManager(VDXLSTMManager):
    def __init__(self, shard_size=100):
        self.shard_size = shard_size
        self.shards = {}
    
    def assign_shard(self, vd_id):
        """å°‡VDåˆ†é…åˆ°ä¸åŒçš„GPUåˆ†ç‰‡"""
        shard_idx = hash(vd_id) % self.num_shards
        return shard_idx
```

### 7.5 æ€§èƒ½ç›£æ§

#### 7.5.1 é—œéµæŒ‡æ¨™
```python
# è¨“ç·´ç›£æ§æŒ‡æ¨™
class PerformanceMonitor:
    def __init__(self):
        self.metrics = {
            'memory_usage': [],         # GPUè¨˜æ†¶é«”ä½¿ç”¨
            'forward_time': [],         # å‰å‘å‚³æ’­æ™‚é–“
            'backward_time': [],        # åå‘å‚³æ’­æ™‚é–“
            'social_pooling_time': [],  # ç¤¾æœƒèšåˆæ™‚é–“
            'gradient_norm': []         # æ¢¯åº¦ç¯„æ•¸
        }
    
    def log_step_metrics(self, step_info):
        """è¨˜éŒ„æ¯æ­¥é©Ÿçš„æ€§èƒ½æŒ‡æ¨™"""
        for key, value in step_info.items():
            if key in self.metrics:
                self.metrics[key].append(value)
```

#### 7.5.2 ç“¶é ¸åˆ†æ
```python
# æ€§èƒ½ç“¶é ¸æª¢æ¸¬
import torch.profiler

def profile_model_step(model, batch):
    """åˆ†ææ¨¡å‹åŸ·è¡Œç“¶é ¸"""
    with torch.profiler.profile(
        activities=[
            torch.profiler.ProfilerActivity.CPU,
            torch.profiler.ProfilerActivity.CUDA,
        ],
        record_shapes=True,
        profile_memory=True,
    ) as prof:
        
        # åŸ·è¡Œä¸€æ­¥è¨“ç·´
        output = model(batch)
        loss = output.sum()
        loss.backward()
    
    # è¼¸å‡ºåˆ†æå ±å‘Š
    print(prof.key_averages().table(sort_by="cuda_time_total", row_limit=10))
```

### 7.6 éƒ¨ç½²å„ªåŒ–

#### 7.6.1 æ¨¡å‹å£“ç¸®
```python
# é‡åŒ–å£“ç¸®
def quantize_model(model):
    """å°‡æ¨¡å‹é‡åŒ–ç‚º int8 ä»¥æ¸›å°‘è¨˜æ†¶é«”"""
    quantized_model = torch.quantization.quantize_dynamic(
        model, 
        {nn.Linear}, 
        dtype=torch.qint8
    )
    return quantized_model

# çŸ¥è­˜è’¸é¤¾
class StudentModel(nn.Module):
    """æ›´å°çš„å­¸ç”Ÿæ¨¡å‹"""
    def __init__(self):
        super().__init__()
        # æ¸›å°‘åƒæ•¸çš„ç°¡åŒ–æ¶æ§‹
        self.xlstm_config.embedding_dim = 64    # 128 â†’ 64
        self.xlstm_config.num_blocks = 4        # 6 â†’ 4
```

#### 7.6.2 æ¨è«–å„ªåŒ–
```python
# æ¨è«–å°ˆç”¨å„ªåŒ–
@torch.no_grad()
def inference_optimized(model, batch):
    """æ¨è«–å„ªåŒ–ç‰ˆæœ¬"""
    model.eval()
    
    # é—œé–‰æ¢¯åº¦è¨ˆç®—
    with torch.inference_mode():
        # ä½¿ç”¨ fp16 æ¨è«–
        with torch.cuda.amp.autocast():
            predictions = model(batch)
    
    return predictions

# æ‰¹æ¬¡æ¨è«–
def batch_inference(model, data_loader, batch_size=64):
    """æ‰¹æ¬¡æ¨è«–è™•ç†"""
    all_predictions = []
    
    for batch in data_loader:
        predictions = inference_optimized(model, batch)
        all_predictions.append(predictions)
    
    return torch.cat(all_predictions, dim=0)
```

---

## 8. é™„éŒ„

### 8.1 å¼µé‡å½¢ç‹€åƒè€ƒ

#### A.1 ä¸»è¦å¼µé‡æ ¼å¼
```python
# è¼¸å…¥å¼µé‡
vd_inputs: Dict[str, torch.Tensor]
# æ ¼å¼: {"VD_ID": Tensor[B, T, F]}
# ç¯„ä¾‹: {"VD-001": Tensor[4, 12, 3]}

# ä½ç½®å¼µé‡  
positions: Dict[str, torch.Tensor]
# æ ¼å¼: {"VD_ID": Tensor[B, T, 2]}  # (x, y) åº§æ¨™
# ç¯„ä¾‹: {"VD-001": Tensor[4, 12, 2]}

# éš±ç‹€æ…‹å¼µé‡
hidden_states: Dict[str, torch.Tensor] 
# æ ¼å¼: {"VD_ID": Tensor[B, T, H]}
# ç¯„ä¾‹: {"VD-001": Tensor[4, 12, 128]}

# ç¤¾æœƒè„ˆçµ¡å¼µé‡
social_contexts: Dict[str, torch.Tensor]
# æ ¼å¼: {"VD_ID": Tensor[B, H]}
# ç¯„ä¾‹: {"VD-001": Tensor[4, 128]}

# é æ¸¬å¼µé‡
predictions: Dict[str, torch.Tensor]
# æ ¼å¼: {"VD_ID": Tensor[B, P, F]}  # P=prediction_length
# ç¯„ä¾‹: {"VD-001": Tensor[4, 1, 3]}
```

#### A.2 æ‰¹æ¬¡ç¶­åº¦èªªæ˜
- **B (Batch)**: æ‰¹æ¬¡å¤§å°ï¼Œé€šå¸¸ç‚º 4, 8, 16, 32
- **T (Time)**: æ™‚é–“æ­¥é•·ï¼Œè¼¸å…¥åºåˆ—é€šå¸¸ç‚º 12
- **N (VDs)**: VD æ•¸é‡ï¼Œå‹•æ…‹è®ŠåŒ–
- **F (Features)**: ç‰¹å¾µç¶­åº¦ï¼Œäº¤é€šæ•¸æ“šç‚º 3
- **H (Hidden)**: éš±ç‹€æ…‹ç¶­åº¦ï¼Œé è¨­ç‚º 128
- **P (Prediction)**: é æ¸¬é•·åº¦ï¼Œé€šå¸¸ç‚º 1 æˆ– 3

### 8.2 éŒ¯èª¤è™•ç†æŒ‡å—

#### B.1 å¸¸è¦‹éŒ¯èª¤é¡å‹
```python
# å¼µé‡å½¢ç‹€ä¸åŒ¹é…
RuntimeError: Expected input tensor to have shape [B, T, 3], got [B, T, 9]
# è§£æ±º: æª¢æŸ¥å¤šVDæ¨¡å¼ä¸‹çš„ç‰¹å¾µç¶­åº¦å±•å¹³

# è¨­å‚™ä¸åŒ¹é…  
RuntimeError: Expected all tensors to be on the same device
# è§£æ±º: ç¢ºä¿æ‰€æœ‰å¼µé‡ç§»å‹•åˆ°ç›¸åŒè¨­å‚™

# è¨˜æ†¶é«”ä¸è¶³
RuntimeError: CUDA out of memory
# è§£æ±º: æ¸›å°‘æ‰¹æ¬¡å¤§å°æˆ–å•Ÿç”¨æ¢¯åº¦æª¢æŸ¥é»

# VDä¸å­˜åœ¨
KeyError: VD model 'VD-XXX-XXX' not found
# è§£æ±º: æª¢æŸ¥lazy_initè¨­å®šæˆ–æ‰‹å‹•åˆå§‹åŒ–VD
```

#### B.2 èª¿è©¦å·¥å…·
```python
# å¼µé‡å½¢ç‹€æª¢æŸ¥
def debug_tensor_shapes(tensor_dict, name=""):
    """æª¢æŸ¥å¼µé‡å½¢ç‹€æ˜¯å¦ç¬¦åˆé æœŸ"""
    print(f"=== {name} Tensor Shapes ===")
    for key, tensor in tensor_dict.items():
        print(f"{key}: {tensor.shape} ({tensor.dtype}) [{tensor.device}]")

# NaN æª¢æ¸¬
def check_nan_values(tensor_dict, step=""):
    """æª¢æ¸¬å¼µé‡ä¸­çš„ NaN å€¼"""
    for key, tensor in tensor_dict.items():
        if torch.isnan(tensor).any():
            print(f"WARNING: NaN detected in {key} at step {step}")
            return True
    return False

# è¨˜æ†¶é«”ç›£æ§
def monitor_gpu_memory():
    """ç›£æ§GPUè¨˜æ†¶é«”ä½¿ç”¨æƒ…æ³"""
    if torch.cuda.is_available():
        memory_used = torch.cuda.memory_allocated() / 1024**3  # GB
        memory_total = torch.cuda.get_device_properties(0).total_memory / 1024**3
        print(f"GPU Memory: {memory_used:.2f}/{memory_total:.2f} GB")
```

### 8.3 é…ç½®ç¯„æœ¬

#### C.1 é–‹ç™¼ç’°å¢ƒé…ç½®
```yaml
# cfgs/environments/development.yaml
environment: "development"
debug: true
logging_level: "DEBUG"

model:
  xlstm:
    num_blocks: 2        # æ¸›å°‘å€å¡Šæ•¸ä»¥åŠ å¿«é–‹ç™¼
    embedding_dim: 64    # æ¸›å°‘ç¶­åº¦ä»¥ç¯€çœè¨˜æ†¶é«”

training:
  epochs: 5            # å¿«é€Ÿé©—è­‰
  batch_size: 4        # å°æ‰¹æ¬¡
  fast_dev_run: true   # PyTorch Lightning å¿«é€Ÿé©—è­‰æ¨¡å¼

data:
  subset_size: 1000    # ä½¿ç”¨æ•¸æ“šå­é›†
```

#### C.2 ç”Ÿç”¢ç’°å¢ƒé…ç½®
```yaml  
# cfgs/environments/production.yaml
environment: "production"
debug: false
logging_level: "INFO"

model:
  xlstm:
    num_blocks: 6        # å®Œæ•´æ¨¡å‹
    embedding_dim: 128   # æ¨™æº–ç¶­åº¦

training:
  epochs: 50           # å®Œæ•´è¨“ç·´
  batch_size: 16       # æ¨™æº–æ‰¹æ¬¡
  gradient_checkpointing: true  # è¨˜æ†¶é«”å„ªåŒ–

optimization:
  mixed_precision: true
  compile_model: true  # PyTorch 2.0 ç·¨è­¯å„ªåŒ–
```

#### C.3 æ¶ˆèç ”ç©¶é…ç½®
```yaml
# cfgs/experiments/ablation_study.yaml
experiment_name: "social_pooling_ablation"

variations:
  - name: "no_social"
    social:
      enabled: false
  
  - name: "mean_pooling"  
    social:
      enabled: true
      aggregation_method: "mean"
  
  - name: "weighted_mean"
    social:
      enabled: true
      aggregation_method: "weighted_mean"
  
  - name: "attention"
    social:
      enabled: true
      aggregation_method: "attention"
```

### 8.4 æ€§èƒ½åŸºæº–

#### D.1 ç¡¬é«”é…ç½®åŸºæº–
```python
# æ¸¬è©¦ç’°å¢ƒé…ç½®
TEST_CONFIGURATIONS = {
    "small": {
        "gpu": "RTX 3080 (10GB)",
        "batch_size": 8,
        "num_vds": 5,
        "sequence_length": 12
    },
    "medium": {
        "gpu": "RTX 4090 (24GB)", 
        "batch_size": 16,
        "num_vds": 10,
        "sequence_length": 12
    },
    "large": {
        "gpu": "A100 (40GB)",
        "batch_size": 32,
        "num_vds": 20, 
        "sequence_length": 12
    }
}
```

#### D.2 æ€§èƒ½åŸºæº–æ•¸æ“š
| é…ç½® | è¨“ç·´æ™‚é–“/Epoch | æ¨è«–æ™‚é–“/Batch | GPUè¨˜æ†¶é«” | æº–ç¢ºåº¦ (MAE) |
|------|----------------|----------------|-----------|--------------|
| **Small** | 45s | 12ms | 6.2GB | 0.156 |
| **Medium** | 78s | 18ms | 11.8GB | 0.142 |
| **Large** | 125s | 28ms | 22.4GB | 0.138 |

#### D.3 æ“´å±•æ€§æ¸¬è©¦
```python
# æ“´å±•æ€§æ¸¬è©¦è…³æœ¬
def scalability_test():
    """æ¸¬è©¦æ¨¡å‹åœ¨ä¸åŒVDæ•¸é‡ä¸‹çš„æ€§èƒ½"""
    vd_counts = [5, 10, 20, 50, 100]
    results = {}
    
    for num_vds in vd_counts:
        # å‰µå»ºæ¸¬è©¦æ•¸æ“š
        test_data = create_test_batch(num_vds=num_vds)
        
        # æ¸¬é‡è¨“ç·´æ™‚é–“
        start_time = time.time()
        model.train_step(test_data)
        train_time = time.time() - start_time
        
        # æ¸¬é‡æ¨è«–æ™‚é–“
        start_time = time.time()
        with torch.no_grad():
            predictions = model(test_data)
        inference_time = time.time() - start_time
        
        # æ¸¬é‡è¨˜æ†¶é«”ä½¿ç”¨
        memory_used = torch.cuda.memory_allocated() / 1024**3
        
        results[num_vds] = {
            'train_time': train_time,
            'inference_time': inference_time,
            'memory_gb': memory_used
        }
    
    return results
```

---

## ğŸ“š åƒè€ƒæ–‡ç»èˆ‡æ“´å±•é–±è®€

1. **Alahi et al. (2016)** - Social LSTM: Human Trajectory Prediction in Crowded Spaces
2. **Beck et al. (2024)** - xLSTM: Extended Long Short-Term Memory  
3. **PyTorch Lightning Documentation** - åˆ†æ•£å¼è¨“ç·´æœ€ä½³å¯¦è¸
4. **Social-xLSTM å°ˆæ¡ˆæ–‡æª”** - `docs/guides/` ç›®éŒ„ä¸‹çš„ç›¸é—œæŒ‡å—

---

## ğŸ”§ ç¶­è­·èˆ‡æ›´æ–°

**æ–‡æª”ç‰ˆæœ¬**: v1.0  
**æœ€å¾Œæ›´æ–°**: 2025-01-15  
**ç¶­è­·è²¬ä»»**: Social-xLSTM é–‹ç™¼åœ˜éšŠ  

**æ›´æ–°è¨˜éŒ„**:
- v1.0 (2025-01-15): åˆå§‹ç‰ˆæœ¬ï¼Œå®Œæ•´æ¶æ§‹èªªæ˜
- å¾…æ›´æ–°: æ ¹æ“šå¯¦éš›éƒ¨ç½²ç¶“é©—è£œå……æ€§èƒ½èª¿å„ªå»ºè­°

**è²¢ç»æŒ‡å—**: å¦‚éœ€æ›´æ–°æ­¤æ–‡æª”ï¼Œè«‹ç¢ºä¿ï¼š
1. æ›´æ–°ä»£ç¢¼è¡Œè™Ÿæ˜ å°„
2. é©—è­‰é…ç½®ç¯„ä¾‹çš„æœ‰æ•ˆæ€§  
3. è£œå……å¯¦éš›æ€§èƒ½æ•¸æ“š
4. éµå¾ªæ—¢å®šçš„æ–‡æª”æ ¼å¼

---

*æœ¬æ–‡æª”æ˜¯ Social-xLSTM å°ˆæ¡ˆçš„æ ¸å¿ƒæŠ€è¡“åƒè€ƒï¼Œç‚ºé–‹ç™¼è€…èˆ‡ç ”ç©¶è€…æä¾›å®Œæ•´çš„æ¶æ§‹ç†è§£å’Œå¯¦æ–½æŒ‡å°ã€‚*