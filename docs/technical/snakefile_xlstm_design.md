# Snakefile xLSTM æ•´åˆè¨­è¨ˆ

**æ—¥æœŸ**: 2025-07-13  
**ä¾æ“š**: ADR-0501 xLSTM æ•´åˆç­–ç•¥  
**ç›®æ¨™**: è¨­è¨ˆä¸¦è¡Œ LSTM/xLSTM è¨“ç·´å·¥ä½œæµç¨‹  

## ğŸ“‹ è¨­è¨ˆç›®æ¨™

### æ ¸å¿ƒéœ€æ±‚
1. **ä¸¦è¡Œè¨“ç·´**: LSTM å’Œ xLSTM å¯åŒæ™‚è¨“ç·´ï¼Œç„¡éœ€åˆ‡æ›é…ç½®æ–‡ä»¶
2. **é…ç½®åˆ†é›¢**: å„è‡ªæœ‰å°ˆé–€çš„é…ç½®å€å¡Šï¼Œåƒæ•¸äº’ä¸å¹²æ“¾
3. **çµæœæ¯”è¼ƒ**: çµ±ä¸€çš„è¼¸å‡ºæ ¼å¼ï¼Œä¾¿æ–¼æ€§èƒ½æ¯”è¼ƒ
4. **å‘å¾Œå…¼å®¹**: ç¾æœ‰ LSTM å·¥ä½œæµç¨‹ä¿æŒä¸è®Š

### æŠ€è¡“è¦æ±‚
- æ”¯æŒä¸‰ç¨®è¨“ç·´æ¨¡å¼ï¼šSingle VD, Multi-VD, Independent Multi-VD
- æ¯ç¨®æ¨¡å¼éƒ½æœ‰ LSTM å’Œ xLSTM ç‰ˆæœ¬ï¼ˆå…±6å€‹è¨“ç·´è¦å‰‡ï¼‰
- çµ±ä¸€çš„å ±å‘Šå’Œè¦–è¦ºåŒ–ç”Ÿæˆ
- è‡ªå‹•åŒ–çš„æ€§èƒ½æ¯”è¼ƒè¦å‰‡

## ğŸ—ï¸ é…ç½®çµæ§‹è¨­è¨ˆ

### ç•¶å‰é…ç½®çµæ§‹ï¼ˆç¾æœ‰ï¼‰
```yaml
# cfgs/snakemake/default.yaml
training:
  single_vd:
    model_type: "lstm"
    experiment_dir: "blob/experiments/dev/single_vd"
    epochs: 100
    batch_size: 32
    # ... å…¶ä»– LSTM åƒæ•¸
```

### æ–°å¢ xLSTM é…ç½®çµæ§‹ï¼ˆæè­°ï¼‰
```yaml
# cfgs/snakemake/default.yaml  
training:
  # ç¾æœ‰ LSTM é…ç½®ä¿æŒä¸è®Š
  single_vd:
    model_type: "lstm"
    experiment_dir: "blob/experiments/dev/single_vd_lstm"
    epochs: 100
    batch_size: 32
    sequence_length: 20
    # LSTM ç‰¹æœ‰åƒæ•¸
    hidden_size: 256
    num_layers: 3
    dropout: 0.3
    
  multi_vd:
    model_type: "lstm"
    experiment_dir: "blob/experiments/dev/multi_vd_lstm"
    # ... LSTM Multi-VD åƒæ•¸
    
  independent_multi_vd:
    model_type: "lstm" 
    experiment_dir: "blob/experiments/dev/independent_multi_vd_lstm"
    # ... LSTM Independent Multi-VD åƒæ•¸

# æ–°å¢ xLSTM é…ç½®å€å¡Š
training_xlstm:
  single_vd:
    model_type: "xlstm"
    experiment_dir: "blob/experiments/dev/single_vd_xlstm"
    epochs: 100
    batch_size: 32
    sequence_length: 20
    # xLSTM ç‰¹æœ‰åƒæ•¸
    embedding_dim: 128
    num_blocks: 6
    slstm_at: [1, 3]
    slstm_backend: "vanilla"
    mlstm_backend: "vanilla"
    dropout: 0.1
    context_length: 256
    
  multi_vd:
    model_type: "xlstm"
    experiment_dir: "blob/experiments/dev/multi_vd_xlstm"
    epochs: 100
    batch_size: 16  # å¯èƒ½éœ€è¦è¼ƒå°çš„ batch size
    sequence_length: 20
    # xLSTM Multi-VD ç‰¹æœ‰åƒæ•¸
    embedding_dim: 128
    num_blocks: 6
    slstm_at: [1, 3, 5]
    num_vds: 10
    dropout: 0.1
    
  independent_multi_vd:
    model_type: "xlstm"
    experiment_dir: "blob/experiments/dev/independent_multi_vd_xlstm"
    epochs: 100
    batch_size: 16
    sequence_length: 20
    # xLSTM Independent Multi-VD åƒæ•¸
    embedding_dim: 128
    num_blocks: 6
    slstm_at: [1, 3]
    num_vds: 10
    target_vd_index: 0
    dropout: 0.1
```

## ğŸ”§ Snakefile è¦å‰‡è¨­è¨ˆ

### æ–°å¢ xLSTM è¨“ç·´è¦å‰‡

```python
# Snakefile æ–°å¢è¦å‰‡

# xLSTM Single VD è¨“ç·´
rule train_single_vd_xlstm:
    input:
        h5_file=config['dataset']['pre-processed']['h5']['file']
    output:
        model_file=os.path.join(config['training_xlstm']['single_vd']['experiment_dir'], "best_model.pt"),
        config_file=os.path.join(config['training_xlstm']['single_vd']['experiment_dir'], "config.json"),
        training_history=os.path.join(config['training_xlstm']['single_vd']['experiment_dir'], "training_history.json")
    log:
        config['training_xlstm']['single_vd']['log']
    params:
        epochs=config['training_xlstm']['single_vd']['epochs'],
        batch_size=config['training_xlstm']['single_vd']['batch_size'],
        sequence_length=config['training_xlstm']['single_vd']['sequence_length'],
        model_type=config['training_xlstm']['single_vd']['model_type'],
        experiment_name=os.path.basename(config['training_xlstm']['single_vd']['experiment_dir']),
        embedding_dim=config['training_xlstm']['single_vd']['embedding_dim'],
        num_blocks=config['training_xlstm']['single_vd']['num_blocks'],
        slstm_at=config['training_xlstm']['single_vd']['slstm_at']
    shell:
        """
        python scripts/train/without_social_pooling/train_single_vd.py \
        --data_path {input.h5_file} \
        --epochs {params.epochs} \
        --batch_size {params.batch_size} \
        --sequence_length {params.sequence_length} \
        --model_type {params.model_type} \
        --experiment_name {params.experiment_name} \
        --save_dir $(dirname $(dirname {output.model_file})) \
        --embedding_dim {params.embedding_dim} \
        --num_blocks {params.num_blocks} \
        --slstm_at {params.slstm_at} >> {log} 2>&1
        """

# xLSTM Multi-VD è¨“ç·´
rule train_multi_vd_xlstm:
    input:
        h5_file=config['dataset']['pre-processed']['h5']['file']
    output:
        training_history=os.path.join(config['training_xlstm']['multi_vd']['experiment_dir'], "training_history.json"),
        model_file=os.path.join(config['training_xlstm']['multi_vd']['experiment_dir'], "best_model.pth")
    log:
        config['training_xlstm']['multi_vd']['log']
    params:
        epochs=config['training_xlstm']['multi_vd']['epochs'],
        batch_size=config['training_xlstm']['multi_vd']['batch_size'],
        sequence_length=config['training_xlstm']['multi_vd']['sequence_length'],
        num_vds=config['training_xlstm']['multi_vd']['num_vds'],
        model_type=config['training_xlstm']['multi_vd']['model_type'],
        experiment_name=os.path.basename(config['training_xlstm']['multi_vd']['experiment_dir']),
        embedding_dim=config['training_xlstm']['multi_vd']['embedding_dim'],
        num_blocks=config['training_xlstm']['multi_vd']['num_blocks'],
        slstm_at=config['training_xlstm']['multi_vd']['slstm_at']
    shell:
        """
        python scripts/train/without_social_pooling/train_multi_vd.py \
        --data_path {input.h5_file} \
        --epochs {params.epochs} \
        --batch_size {params.batch_size} \
        --sequence_length {params.sequence_length} \
        --num_vds {params.num_vds} \
        --model_type {params.model_type} \
        --experiment_name {params.experiment_name} \
        --save_dir $(dirname {output.training_history}) \
        --embedding_dim {params.embedding_dim} \
        --num_blocks {params.num_blocks} \
        --slstm_at {params.slstm_at} >> {log} 2>&1
        """

# xLSTM Independent Multi-VD è¨“ç·´  
rule train_independent_multi_vd_xlstm:
    input:
        h5_file=config['dataset']['pre-processed']['h5']['file']
    output:
        training_history=os.path.join(config['training_xlstm']['independent_multi_vd']['experiment_dir'], "training_history.json"),
        model_file=os.path.join(config['training_xlstm']['independent_multi_vd']['experiment_dir'], "best_model.pth")
    log:
        config['training_xlstm']['independent_multi_vd']['log']
    params:
        epochs=config['training_xlstm']['independent_multi_vd']['epochs'],
        batch_size=config['training_xlstm']['independent_multi_vd']['batch_size'],
        sequence_length=config['training_xlstm']['independent_multi_vd']['sequence_length'],
        num_vds=config['training_xlstm']['independent_multi_vd']['num_vds'],
        target_vd_index=config['training_xlstm']['independent_multi_vd']['target_vd_index'],
        model_type=config['training_xlstm']['independent_multi_vd']['model_type'],
        experiment_name=os.path.basename(config['training_xlstm']['independent_multi_vd']['experiment_dir']),
        embedding_dim=config['training_xlstm']['independent_multi_vd']['embedding_dim'],
        num_blocks=config['training_xlstm']['independent_multi_vd']['num_blocks'],
        slstm_at=config['training_xlstm']['independent_multi_vd']['slstm_at']
    shell:
        """
        python scripts/train/without_social_pooling/train_independent_multi_vd.py \
        --data_path {input.h5_file} \
        --epochs {params.epochs} \
        --batch_size {params.batch_size} \
        --sequence_length {params.sequence_length} \
        --num_vds {params.num_vds} \
        --target_vd_index {params.target_vd_index} \
        --model_type {params.model_type} \
        --experiment_name {params.experiment_name} \
        --save_dir $(dirname {output.training_history}) \
        --embedding_dim {params.embedding_dim} \
        --num_blocks {params.num_blocks} \
        --slstm_at {params.slstm_at} >> {log} 2>&1
        """
```

### æ€§èƒ½æ¯”è¼ƒè¦å‰‡

```python
# æ–°å¢ LSTM vs xLSTM æ¯”è¼ƒè¦å‰‡
rule compare_lstm_xlstm_single_vd:
    input:
        lstm_history=rules.train_single_vd_without_social_pooling.output.training_history,
        xlstm_history=rules.train_single_vd_xlstm.output.training_history
    output:
        comparison_report="blob/experiments/dev/comparison/single_vd_lstm_vs_xlstm.md",
        comparison_plots="blob/experiments/dev/comparison/single_vd_plots/"
    log:
        "logs/comparison/single_vd_lstm_vs_xlstm.log"
    shell:
        """
        python scripts/utils/compare_models.py \
        --lstm_experiment_dir $(dirname {input.lstm_history}) \
        --xlstm_experiment_dir $(dirname {input.xlstm_history}) \
        --output_report {output.comparison_report} \
        --output_plots_dir {output.comparison_plots} \
        --comparison_name "Single VD: LSTM vs xLSTM" >> {log} 2>&1
        """

rule compare_lstm_xlstm_multi_vd:
    input:
        lstm_history=rules.train_multi_vd_without_social_pooling.output.training_history,
        xlstm_history=rules.train_multi_vd_xlstm.output.training_history
    output:
        comparison_report="blob/experiments/dev/comparison/multi_vd_lstm_vs_xlstm.md",
        comparison_plots="blob/experiments/dev/comparison/multi_vd_plots/"
    log:
        "logs/comparison/multi_vd_lstm_vs_xlstm.log"
    shell:
        """
        python scripts/utils/compare_models.py \
        --lstm_experiment_dir $(dirname {input.lstm_history}) \
        --xlstm_experiment_dir $(dirname {input.xlstm_history}) \
        --output_report {output.comparison_report} \
        --output_plots_dir {output.comparison_plots} \
        --comparison_name "Multi-VD: LSTM vs xLSTM" >> {log} 2>&1
        """

rule compare_lstm_xlstm_independent_multi_vd:
    input:
        lstm_history=rules.train_independent_multi_vd_without_social_pooling.output.training_history,
        xlstm_history=rules.train_independent_multi_vd_xlstm.output.training_history
    output:
        comparison_report="blob/experiments/dev/comparison/independent_multi_vd_lstm_vs_xlstm.md",
        comparison_plots="blob/experiments/dev/comparison/independent_multi_vd_plots/"
    log:
        "logs/comparison/independent_multi_vd_lstm_vs_xlstm.log"  
    shell:
        """
        python scripts/utils/compare_models.py \
        --lstm_experiment_dir $(dirname {input.lstm_history}) \
        --xlstm_experiment_dir $(dirname {input.xlstm_history}) \
        --output_report {output.comparison_report} \
        --output_plots_dir {output.comparison_plots} \
        --comparison_name "Independent Multi-VD: LSTM vs xLSTM" >> {log} 2>&1
        """

# ç¶œåˆæ¯”è¼ƒè¦å‰‡
rule compare_all_models:
    input:
        single_vd_comparison="blob/experiments/dev/comparison/single_vd_lstm_vs_xlstm.md",
        multi_vd_comparison="blob/experiments/dev/comparison/multi_vd_lstm_vs_xlstm.md", 
        independent_multi_vd_comparison="blob/experiments/dev/comparison/independent_multi_vd_lstm_vs_xlstm.md"
    output:
        comprehensive_report="blob/experiments/dev/comparison/comprehensive_model_comparison.md"
    log:
        "logs/comparison/comprehensive_comparison.log"
    shell:
        """
        python scripts/utils/generate_comprehensive_comparison.py \
        --input_reports {input.single_vd_comparison} {input.multi_vd_comparison} {input.independent_multi_vd_comparison} \
        --output_report {output.comprehensive_report} >> {log} 2>&1
        """
```

## ğŸ“Š ä½¿ç”¨æµç¨‹è¨­è¨ˆ

### 1. å–®ç¨è¨“ç·´ LSTMï¼ˆç¾æœ‰åŠŸèƒ½ï¼‰
```bash
# è¨“ç·´å–®ä¸€ LSTM æ¨¡å‹
snakemake train_single_vd_without_social_pooling

# è¨“ç·´æ‰€æœ‰ LSTM æ¨¡å‹
snakemake train_multi_vd_without_social_pooling train_independent_multi_vd_without_social_pooling
```

### 2. å–®ç¨è¨“ç·´ xLSTMï¼ˆæ–°åŠŸèƒ½ï¼‰
```bash
# è¨“ç·´å–®ä¸€ xLSTM æ¨¡å‹
snakemake train_single_vd_xlstm

# è¨“ç·´æ‰€æœ‰ xLSTM æ¨¡å‹  
snakemake train_multi_vd_xlstm train_independent_multi_vd_xlstm
```

### 3. ä¸¦è¡Œè¨“ç·´èˆ‡æ¯”è¼ƒï¼ˆæ–°åŠŸèƒ½ï¼‰
```bash
# åŒæ™‚è¨“ç·´ LSTM å’Œ xLSTMï¼Œç„¶å¾Œæ¯”è¼ƒ
snakemake compare_lstm_xlstm_single_vd

# è¨“ç·´æ‰€æœ‰æ¨¡å‹ä¸¦ç”Ÿæˆç¶œåˆæ¯”è¼ƒå ±å‘Š
snakemake compare_all_models
```

### 4. éˆæ´»çš„ç›®æ¨™è¦å‰‡
```bash
# åªè¦ Single VD çš„æ‰€æœ‰çµæœï¼ˆLSTM + xLSTM + æ¯”è¼ƒï¼‰
snakemake compare_lstm_xlstm_single_vd

# è¦æ‰€æœ‰æ¨¡å‹çš„å®Œæ•´æ¯”è¼ƒ
snakemake compare_all_models

# å‚³çµ±æ–¹å¼ï¼šåªè¦ LSTM åŸºæº–
snakemake generate_single_vd_report
```

## ğŸ”„ é…ç½®æ–‡ä»¶æ›´æ–°ç­–ç•¥

### éšæ®µ 1: é…ç½®æ“´å±•
1. åœ¨ `cfgs/snakemake/default.yaml` ä¸­æ·»åŠ  `training_xlstm` å€å¡Š
2. ä¿æŒç¾æœ‰ `training` å€å¡Šå®Œå…¨ä¸è®Š  
3. æ¸¬è©¦é…ç½®æ–‡ä»¶è§£æ

### éšæ®µ 2: è¦å‰‡æ·»åŠ 
1. åœ¨ Snakefile ä¸­æ·»åŠ  xLSTM è¨“ç·´è¦å‰‡
2. æ·»åŠ æ¯”è¼ƒè¦å‰‡
3. æ¸¬è©¦è¦å‰‡ä¾è³´é—œä¿‚

### éšæ®µ 3: è…³æœ¬ä¿®æ”¹
1. ä¿®æ”¹è¨“ç·´è…³æœ¬æ”¯æ´ xLSTM åƒæ•¸
2. å‰µå»ºæ¨¡å‹æ¯”è¼ƒè…³æœ¬
3. æ¸¬è©¦ç«¯åˆ°ç«¯å·¥ä½œæµç¨‹

## âš ï¸ æ³¨æ„äº‹é …

### å‘å¾Œå…¼å®¹æ€§
- ç¾æœ‰çš„ `training` é…ç½®ä¿æŒå®Œå…¨ä¸è®Š
- ç¾æœ‰çš„ LSTM è¨“ç·´è¦å‰‡ä¿æŒä¸è®Š
- å¯ä»¥ç¹¼çºŒå–®ç¨ä½¿ç”¨ LSTM å·¥ä½œæµç¨‹

### å‘½åè¦ç¯„
- LSTM å¯¦é©—ç›®éŒ„: `blob/experiments/dev/single_vd_lstm`
- xLSTM å¯¦é©—ç›®éŒ„: `blob/experiments/dev/single_vd_xlstm`  
- æ¯”è¼ƒçµæœç›®éŒ„: `blob/experiments/dev/comparison/`

### åƒæ•¸èª¿å„ª
- xLSTM å¯èƒ½éœ€è¦è¼ƒå°çš„ batch_sizeï¼ˆè¨˜æ†¶é«”éœ€æ±‚è¼ƒé«˜ï¼‰
- embedding_dim å’Œ num_blocks éœ€è¦æ ¹æ“šå¯¦éš›æƒ…æ³èª¿æ•´
- åˆæœŸä½¿ç”¨ vanilla backend ç¢ºä¿ç©©å®šæ€§

## ğŸ“‹ å¯¦æ–½æª¢æŸ¥æ¸…å–®

- [ ] å‰µå»º `training_xlstm` é…ç½®å€å¡Š
- [ ] ä¿®æ”¹ Snakefile æ·»åŠ  xLSTM è¨“ç·´è¦å‰‡
- [ ] å‰µå»ºæ¨¡å‹æ¯”è¼ƒè…³æœ¬
- [ ] ä¿®æ”¹è¨“ç·´è…³æœ¬æ”¯æ´ xLSTM åƒæ•¸
- [ ] æ¸¬è©¦é…ç½®æ–‡ä»¶è§£æ
- [ ] æ¸¬è©¦å–®ä¸€ xLSTM è¨“ç·´è¦å‰‡
- [ ] æ¸¬è©¦æ¯”è¼ƒè¦å‰‡
- [ ] é©—è­‰å‘å¾Œå…¼å®¹æ€§
- [ ] æ–‡æª”åŒ–æ–°çš„ä½¿ç”¨æµç¨‹

---

**æ–‡æª”ç‹€æ…‹**: è¨­è¨ˆéšæ®µ  
**ç›¸é—œ ADR**: ADR-0501  
**ä¸‹ä¸€æ­¥**: å¯¦æ–½é…ç½®æ–‡ä»¶ä¿®æ”¹