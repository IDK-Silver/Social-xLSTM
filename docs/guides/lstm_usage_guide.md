# LSTM ä½¿ç”¨æŒ‡å—

æœ¬æŒ‡å—èªªæ˜å¦‚ä½•ä½¿ç”¨ Social-xLSTM å°ˆæ¡ˆä¸­çš„çµ±ä¸€ LSTM æ¨¡å‹ (`TrafficLSTM`)ã€‚

## ğŸ“‹ ç›®éŒ„

1. [å¿«é€Ÿé–‹å§‹](#å¿«é€Ÿé–‹å§‹)
2. [æ ¸å¿ƒæ¦‚å¿µ](#æ ¸å¿ƒæ¦‚å¿µ)
3. [åŸºæœ¬ä½¿ç”¨](#åŸºæœ¬ä½¿ç”¨)
4. [å¸¸è¦‹å•é¡Œ](#å¸¸è¦‹å•é¡Œ)

## ğŸš€ å¿«é€Ÿé–‹å§‹

### åŸºæœ¬è¨“ç·´

```bash
# å–®VD LSTM è¨“ç·´
python scripts/train/without_social_pooling/train_single_vd.py

# å¤šVD LSTM è¨“ç·´ï¼ˆç©ºé–“é—œä¿‚ï¼‰
python scripts/train/without_social_pooling/train_multi_vd.py

# ç¨ç«‹å¤šVD LSTM è¨“ç·´ï¼ˆåŸºæº–æ¯”è¼ƒï¼‰
python scripts/train/without_social_pooling/train_independent_multi_vd.py

# ä½¿ç”¨ Snakemake åŸ·è¡Œå®Œæ•´æµç¨‹
snakemake --configfile cfgs/snakemake/dev.yaml --cores 4
```

## ğŸ§  æ ¸å¿ƒæ¦‚å¿µ

### ä»€éº¼æ˜¯ VD (Vehicle Detector)ï¼Ÿ
VD æ˜¯è·¯é‚Šçš„è»Šæµç›£æ¸¬å™¨ï¼Œæ¯å€‹VDæä¾›ä»¥ä¸‹æ•¸æ“šï¼š
- **volume**: è»Šæµé‡
- **speed**: å¹³å‡è»Šé€Ÿ
- **occupancy**: è»Šé“ä½”ç”¨ç‡

### æ•¸æ“šæ ¼å¼
- **è¼¸å…¥**: æ™‚é–“åºåˆ—äº¤é€šæ•¸æ“š
  - 3D å¼µé‡ (batch, sequence, features) - å–®VDæ¨¡å¼
  - 4D å¼µé‡ (batch, sequence, vd_count, features) - å¤šVDæ¨¡å¼
- **è¼¸å‡º**: é æ¸¬çš„äº¤é€šç‹€æ³
- **ç‰¹å¾µ**: æµé‡ã€é€Ÿåº¦ã€ä½”ç”¨ç‡

### è¨“ç·´å™¨é¡å‹
- **SingleVDTrainer**: å–®VDå°ˆç”¨ï¼Œè™•ç†3Dæ•¸æ“š
- **MultiVDTrainer**: å¤šVDç©ºé–“é—œä¿‚ï¼Œè™•ç†4Dæ•¸æ“š
- **IndependentMultiVDTrainer**: ç¨ç«‹å¤šVDï¼Œæå–å–®VDé€²è¡Œè¨“ç·´

## ğŸ“– åŸºæœ¬ä½¿ç”¨

### 1. æ•¸æ“šæº–å‚™

```bash
# å®Œæ•´æ•¸æ“šè™•ç†æµç¨‹
snakemake --cores 4

# æˆ–æ‰‹å‹•è™•ç†
python scripts/dataset/pre-process/create_h5_file.py \
  --source_dir blob/dataset/unzip_to_json \
  --output_path blob/dataset/pre-processed/h5/traffic_features.h5
```

### 2. æ¨¡å‹è¨“ç·´

#### åŸºæœ¬ LSTM è¨“ç·´

```python
# çµ±ä¸€ LSTM å¯¦ç¾
from social_xlstm.models.lstm import TrafficLSTM
from social_xlstm.dataset import TrafficDatasetConfig, TrafficDataModule
from social_xlstm.training.without_social_pooling import SingleVDTrainer

# å‰µå»ºæ•¸æ“šæ¨¡çµ„
data_module = TrafficDataModule(
    data_path="blob/dataset/pre-processed/h5/traffic_features.h5",
    batch_size=32,
    sequence_length=12
)

# å‰µå»ºæ¨¡å‹
model = TrafficLSTM(
    input_size=3,
    hidden_size=128,
    num_layers=2,
    output_size=3
)

# ä½¿ç”¨å°ˆæ¥­åŒ–è¨“ç·´å™¨
trainer = SingleVDTrainer(
    model=model,
    data_module=data_module,
    learning_rate=0.001,
    experiment_name="lstm_single_vd"
)

# è¨“ç·´
recorder = trainer.train()
```

#### å¤šVD LSTM è¨“ç·´

```python
from social_xlstm.training.without_social_pooling import MultiVDTrainer

# å¤šVDæ¨¡å‹ï¼ˆæ”¯æ´ç©ºé–“é—œä¿‚ï¼‰
model = TrafficLSTM(
    input_size=3,
    hidden_size=256,  # è¼ƒå¤§çš„éš±è—å±¤
    num_layers=2,
    output_size=3,
    multi_vd_mode=True  # å•Ÿç”¨å¤šVDæ¨¡å¼
)

# ä½¿ç”¨å¤šVDè¨“ç·´å™¨
trainer = MultiVDTrainer(
    model=model,
    data_module=data_module,
    learning_rate=0.001,
    experiment_name="lstm_multi_vd"
)

# è¨“ç·´
recorder = trainer.train()
```

#### ç¨ç«‹å¤šVD LSTM è¨“ç·´

```python
from social_xlstm.training.without_social_pooling import IndependentMultiVDTrainer

# å–®VDæ¨¡å‹ï¼ˆç”¨æ–¼ç¨ç«‹è¨“ç·´ï¼‰
model = TrafficLSTM(
    input_size=3,
    hidden_size=128,
    num_layers=2,
    output_size=3,
    multi_vd_mode=False  # å–®VDæ¨¡å¼
)

# ä½¿ç”¨ç¨ç«‹å¤šVDè¨“ç·´å™¨
trainer = IndependentMultiVDTrainer(
    model=model,
    data_module=data_module,
    learning_rate=0.001,
    experiment_name="lstm_independent_multi_vd"
)

# è¨“ç·´
recorder = trainer.train()
```

### 3. æ¨¡å‹è©•ä¼°

```python
from social_xlstm.evaluation.evaluator import ModelEvaluator

# å‰µå»ºè©•ä¼°å™¨
evaluator = ModelEvaluator()

# è©•ä¼°æ¨¡å‹
metrics = evaluator.evaluate(model, test_data)
print(f"MAE: {metrics['mae']:.4f}")
print(f"MSE: {metrics['mse']:.4f}")
print(f"RMSE: {metrics['rmse']:.4f}")
print(f"MAPE: {metrics['mape']:.4f}")
print(f"RÂ²: {metrics['r2']:.4f}")
```

### 4. è¨“ç·´è¨˜éŒ„èˆ‡åˆ†æ

```python
from social_xlstm.training.recorder import TrainingRecorder
from social_xlstm.visualization.training_visualizer import TrainingVisualizer

# è¼‰å…¥è¨“ç·´è¨˜éŒ„
recorder = TrainingRecorder.load("blob/experiments/lstm_single_vd/training_record.json")

# ç²å–è¨“ç·´ç¸½çµ
summary = recorder.get_training_summary()
print(f"ç¸½epochs: {summary['total_epochs']}")
print(f"æœ€ä½³é©—è­‰æå¤±: {summary['best_val_loss']:.4f}")
print(f"æœ€ä½³epoch: {summary['best_epoch']}")

# ç”Ÿæˆè¦–è¦ºåŒ–
visualizer = TrainingVisualizer()
visualizer.plot_training_dashboard(recorder, "training_dashboard.png")
```

## â“ å¸¸è¦‹å•é¡Œ

### Q1: å¦‚ä½•è™•ç†ç¼ºå¤±æ•¸æ“šï¼Ÿ
ä½¿ç”¨ `TrafficDataProcessor` è‡ªå‹•è™•ç†ç¼ºå¤±å€¼ï¼š
```python
from social_xlstm.dataset.core import TrafficDataProcessor

processor = TrafficDataProcessor()
processed_data = processor.process(raw_data)
```

### Q2: å¦‚ä½•é¸æ“‡æ¨¡å‹åƒæ•¸ï¼Ÿ
- **å–®VDæ¨¡å¼**:
  - `hidden_size`: 64-128
  - `num_layers`: 2-3
  - `batch_size`: 32-64
- **å¤šVDæ¨¡å¼**:
  - `hidden_size`: 128-256ï¼ˆè¼ƒå¤§ï¼‰
  - `num_layers`: 2-3
  - `batch_size`: 16-32ï¼ˆè¼ƒå°ï¼‰
- **é€šç”¨åƒæ•¸**:
  - `sequence_length`: 12 å€‹æ™‚é–“æ­¥ï¼ˆ12 åˆ†é˜ï¼‰
  - `learning_rate`: 0.001

### Q3: è¨“ç·´æ™‚é–“éé•·æ€éº¼è¾¦ï¼Ÿ
- æ¸›å°‘æ‰¹æ¬¡å¤§å°
- ä½¿ç”¨ GPU åŠ é€Ÿ
- å•Ÿç”¨æ··åˆç²¾åº¦ï¼š`--mixed_precision`
- æ¸›å°‘æ•¸æ“šé‡é€²è¡Œæ¸¬è©¦

### Q4: å¦‚ä½•é¸æ“‡è¨“ç·´å™¨ï¼Ÿ
- **SingleVDTrainer**: å–®é»é æ¸¬ï¼Œå¿«é€Ÿè¨“ç·´
- **MultiVDTrainer**: ç©ºé–“é—œä¿‚å­¸ç¿’ï¼Œæº–å‚™Social Pooling
- **IndependentMultiVDTrainer**: åŸºæº–æ¯”è¼ƒï¼Œç¨ç«‹VDæ€§èƒ½

### Q5: å¦‚ä½•å¯è¦–åŒ–çµæœï¼Ÿ
```python
from social_xlstm.visualization.training_visualizer import TrainingVisualizer

visualizer = TrainingVisualizer()
visualizer.plot_basic_training_curves(recorder, "training_curves.png")
```

### Q6: è¨“ç·´å¤±æ•—å¦‚ä½•èª¿è©¦ï¼Ÿ
1. æª¢æŸ¥æ•¸æ“šè·¯å¾‘ï¼š`blob/dataset/pre-processed/h5/traffic_features.h5`
2. ç¢ºèªcondaç’°å¢ƒï¼š`conda activate social_xlstm`
3. æŸ¥çœ‹æ—¥èªŒï¼š`logs/training.log`
4. é™ä½å­¸ç¿’ç‡ï¼š`--learning_rate 0.0001`
5. æª¢æŸ¥æ¢¯åº¦ç¯„æ•¸ï¼šä½¿ç”¨ `TrainingRecorder` ç›£æ§

## ğŸ”— ç›¸é—œæ–‡æª”

- [æ¨¡çµ„åŠŸèƒ½èªªæ˜](../implementation/modules.md)
- [è¨“ç·´è…³æœ¬ä½¿ç”¨æŒ‡å—](training_scripts_guide.md)
- [çµ±ä¸€è¨“ç·´ç³»çµ±ä½¿ç”¨æŒ‡å—](trainer_usage_guide.md)
- [è¨“ç·´è¨˜éŒ„å™¨ä½¿ç”¨æŒ‡å—](training_recorder_guide.md)
- [Social xLSTM æ¶æ§‹è¨­è¨ˆ](../architecture/social_xlstm_design.md)
- [å°ˆæ¡ˆæ¦‚è¿°](../overview/project_overview.md)

## ğŸ“Š å¯¦éš›ç¯„ä¾‹

### å®Œæ•´è¨“ç·´æµç¨‹

```bash
# 1. ç¢ºä¿ç’°å¢ƒ
conda activate social_xlstm

# 2. æº–å‚™æ•¸æ“š
snakemake --cores 4

# 3. è¨“ç·´æ¨¡å‹
python scripts/train/without_social_pooling/train_single_vd.py \
  --epochs 100 \
  --batch_size 32 \
  --hidden_size 128 \
  --experiment_name "my_lstm_experiment"

# 4. æŸ¥çœ‹çµæœ
ls blob/experiments/my_lstm_experiment/
```

### æ‰¹é‡å¯¦é©—

```bash
# ä¸¦è¡ŒåŸ·è¡Œæ‰€æœ‰è¨“ç·´
snakemake train_single_vd_without_social_pooling \
         train_multi_vd_without_social_pooling \
         train_independent_multi_vd_without_social_pooling \
         --cores 3
```

### çµæœåˆ†æ

```python
# æ¯”è¼ƒä¸åŒè¨“ç·´æ–¹æ³•
from social_xlstm.training.recorder import TrainingRecorder

# è¼‰å…¥è¨˜éŒ„
single_vd = TrainingRecorder.load("blob/experiments/single_vd/training_record.json")
multi_vd = TrainingRecorder.load("blob/experiments/multi_vd/training_record.json")
independent = TrainingRecorder.load("blob/experiments/independent_multi_vd/training_record.json")

# æ¯”è¼ƒçµæœ
comparison = single_vd.compare_with(multi_vd)
print(f"æ›´ä½³æ–¹æ³•: {comparison['better_performer']}")
print(f"æ€§èƒ½å·®ç•°: {comparison['loss_difference']:.4f}")
```

## ğŸ“ æ”¯æ´

å¦‚æœ‰å•é¡Œï¼Œè«‹åƒè€ƒï¼š
1. ğŸ“– å°ˆæ¡ˆæ–‡æª” (`docs/` ç›®éŒ„)
2. ğŸ’» ç¯„ä¾‹ä»£ç¢¼ (`scripts/train/without_social_pooling/`)
3. ğŸ› GitHub Issues
4. ğŸ” å¿«é€Ÿåˆå§‹åŒ–ï¼š`python scripts/utils/claude_init.py --quick`
5. ğŸ“Š æ¸¬è©¦è…³æœ¬ï¼š`python scripts/train/test_training_scripts.py --quick`

### æ•…éšœæ’é™¤

**å¸¸è¦‹éŒ¯èª¤**ï¼š
- `ModuleNotFoundError`: ç¢ºä¿ä½¿ç”¨ `pip install -e .` å®‰è£
- `CUDA out of memory`: é™ä½ batch_size æˆ–å•Ÿç”¨æ··åˆç²¾åº¦
- `æ•¸æ“šæ–‡ä»¶ä¸å­˜åœ¨`: é‹è¡Œ `snakemake --cores 4` ç”Ÿæˆæ•¸æ“š
- `condaç’°å¢ƒå•é¡Œ`: ç¢ºèªä½¿ç”¨ `conda activate social_xlstm`

**æ€§èƒ½èª¿å„ª**ï¼š
- å–®VDï¼šbatch_size=32-64, hidden_size=128
- å¤šVDï¼šbatch_size=16-32, hidden_size=256
- å•Ÿç”¨æ··åˆç²¾åº¦ï¼š`--mixed_precision`
- ä½¿ç”¨GPUï¼šç¢ºä¿CUDAå¯ç”¨