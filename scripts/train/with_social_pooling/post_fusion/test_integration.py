#!/usr/bin/env python3
"""
Post-Fusion Integration Test Script

This script validates the complete Post-Fusion Social Pooling integration
without running full training. It tests:
- Configuration loading and validation
- Coordinate data processing
- Model creation and initialization
- Data flow through the complete pipeline

Usage:
    python test_integration.py --coordinate_data data/sample_vd_coordinates.json --select_vd_id VD-C1T0440-N

Author: Social-xLSTM Project Team
"""

import sys
import os
import argparse
from pathlib import Path

# Add project root to Python path
sys.path.insert(0, str(Path(__file__).parent.parent.parent.parent.parent))

import torch
import json

# Import testing utilities
from common import (
    setup_logging, add_post_fusion_arguments, validate_post_fusion_setup,
    create_social_pooling_config_from_args, load_coordinate_data,
    create_social_data_module, create_post_fusion_model
)


def test_configuration_loading(args, logger):
    """Test Social Pooling configuration creation."""
    logger.info("Testing configuration loading...")
    
    # Test configuration creation
    social_config = create_social_pooling_config_from_args(args, logger)
    
    # Validate configuration
    assert social_config.pooling_radius > 0, "Invalid pooling radius"
    assert social_config.max_neighbors > 0, "Invalid max neighbors"
    
    logger.info(f"‚úÖ Configuration test passed: {social_config}")
    return social_config


def test_coordinate_loading(args, logger):
    """Test coordinate data loading and validation."""
    logger.info("Testing coordinate data loading...")
    
    # Test coordinate loading
    coordinates = load_coordinate_data(args.coordinate_data, logger)
    
    # Validate coordinates
    assert len(coordinates) > 0, "No coordinates loaded"
    assert args.select_vd_id in coordinates, f"Selected VD {args.select_vd_id} not in coordinates"
    
    # Validate coordinate format
    for vd_id, coord in coordinates.items():
        assert isinstance(coord, tuple), f"Invalid coordinate format for {vd_id}"
        assert len(coord) == 2, f"Coordinate should have 2 elements for {vd_id}"
        assert all(isinstance(x, (int, float)) for x in coord), f"Coordinate values should be numeric for {vd_id}"
    
    logger.info(f"‚úÖ Coordinate loading test passed: {len(coordinates)} VDs loaded")
    return coordinates


def test_data_module_creation(args, coordinates, logger):
    """Test data module creation with coordinate support."""
    logger.info("Testing data module creation...")
    
    # Create data module (this will use a mock data path for testing)
    try:
        # For testing, we'll create a minimal mock data module
        from social_xlstm.dataset.core.datamodule import TrafficDataModule
        from social_xlstm.dataset.config.base import TrafficDatasetConfig
        
        # Create minimal config for testing
        data_config = TrafficDatasetConfig(
            hdf5_path="/tmp/test.h5",  # Mock path
            sequence_length=args.sequence_length,
            batch_size=args.batch_size,
            selected_vdids=[args.select_vd_id],
            train_ratio=0.7,
            val_ratio=0.15,
            test_ratio=0.15,
            num_workers=1
        )
        
        # Mock data module for testing
        class MockTrafficDataModule:
            def __init__(self, config):
                self.config = config
                self.coordinates = None
            
            def setup(self):
                pass
            
            def train_dataloader(self):
                # Return mock batch
                mock_batch = {
                    'input_seq': torch.randn(4, args.sequence_length, 3),  # [batch, seq, features]
                    'target_seq': torch.randn(4, 1, 3)  # [batch, 1, features]
                }
                return [mock_batch]
        
        data_module = MockTrafficDataModule(data_config)
        data_module.coordinates = coordinates
        
        logger.info("‚úÖ Data module creation test passed (mock)")
        return data_module
        
    except Exception as e:
        logger.warning(f"Data module test using mock due to: {e}")
        return None


def test_model_creation(args, data_module, social_config, coordinates, logger):
    """Test Post-Fusion model creation."""
    logger.info("Testing model creation...")
    
    if data_module is None:
        logger.warning("Skipping model creation test (no data module)")
        return None
    
    try:
        # Create model
        model = create_post_fusion_model(args, data_module, social_config, coordinates, logger)
        
        # Validate model structure
        assert hasattr(model, 'base_model'), "Model should have base_model attribute"
        assert hasattr(model, 'social_pooling'), "Model should have social_pooling attribute"
        assert hasattr(model, 'fusion_layer'), "Model should have fusion_layer attribute"
        
        # Test model info
        model_info = model.get_model_info()
        assert 'total_parameters' in model_info, "Model info should include parameter count"
        assert model_info['total_parameters'] > 0, "Model should have parameters"
        
        logger.info(f"‚úÖ Model creation test passed: {model_info['total_parameters']:,} parameters")
        return model
        
    except Exception as e:
        logger.error(f"Model creation test failed: {e}")
        return None


def test_forward_pass(model, args, logger):
    """Test model forward pass."""
    logger.info("Testing model forward pass...")
    
    if model is None:
        logger.warning("Skipping forward pass test (no model)")
        return
    
    try:
        # Create mock input
        batch_size = 2
        seq_len = args.sequence_length
        features = 3
        
        input_seq = torch.randn(batch_size, seq_len, features)
        coordinates_tensor = torch.tensor([[121.5654, 25.0330], [121.5643, 25.0315]], dtype=torch.float32)
        vd_ids = [args.select_vd_id, "VD-C1T0441-S"]
        
        # Test forward pass
        with torch.no_grad():
            output = model(input_seq, coordinates_tensor, vd_ids)
        
        # Validate output
        expected_shape = (batch_size, 1, features)
        assert output.shape == expected_shape, f"Expected output shape {expected_shape}, got {output.shape}"
        assert not torch.isnan(output).any(), "Output contains NaN values"
        assert torch.isfinite(output).all(), "Output contains infinite values"
        
        logger.info(f"‚úÖ Forward pass test passed: output shape {output.shape}")
        
    except Exception as e:
        logger.error(f"Forward pass test failed: {e}")
        import traceback
        logger.error(traceback.format_exc())


def run_integration_tests():
    """Run complete integration test suite."""
    # Parse arguments
    parser = argparse.ArgumentParser(description="Post-Fusion Integration Test")
    add_post_fusion_arguments(parser)
    parser.add_argument("--select_vd_id", type=str, default="VD-C1T0440-N",
                        help="VD ID for testing")
    
    args = parser.parse_args()
    
    # Setup logging
    logger = setup_logging()
    logger.info("Starting Post-Fusion integration tests...")
    
    # Test suite
    tests_passed = 0
    total_tests = 5
    
    try:
        # Test 1: Setup validation
        logger.info("\n" + "="*50)
        logger.info("Test 1: Setup Validation")
        validate_post_fusion_setup(args, logger)
        tests_passed += 1
        
        # Test 2: Configuration loading
        logger.info("\n" + "="*50)
        logger.info("Test 2: Configuration Loading")
        social_config = test_configuration_loading(args, logger)
        tests_passed += 1
        
        # Test 3: Coordinate loading
        logger.info("\n" + "="*50)
        logger.info("Test 3: Coordinate Data Loading")
        coordinates = test_coordinate_loading(args, logger)
        tests_passed += 1
        
        # Test 4: Data module creation
        logger.info("\n" + "="*50)
        logger.info("Test 4: Data Module Creation")
        data_module = test_data_module_creation(args, coordinates, logger)
        tests_passed += 1
        
        # Test 5: Model creation and forward pass
        logger.info("\n" + "="*50)
        logger.info("Test 5: Model Creation and Forward Pass")
        model = test_model_creation(args, data_module, social_config, coordinates, logger)
        if model:
            test_forward_pass(model, args, logger)
        tests_passed += 1
        
    except Exception as e:
        logger.error(f"Test failed: {e}")
        import traceback
        logger.error(traceback.format_exc())
    
    # Results
    logger.info("\n" + "="*60)
    logger.info(f"Integration Test Results: {tests_passed}/{total_tests} tests passed")
    
    if tests_passed == total_tests:
        logger.info("üéâ All integration tests passed!")
        logger.info("Post-Fusion Social Pooling integration is ready for training.")
    else:
        logger.warning(f"‚ö†Ô∏è  {total_tests - tests_passed} tests failed.")
        logger.info("Please check the errors above and fix before training.")
    
    return tests_passed == total_tests


if __name__ == "__main__":
    success = run_integration_tests()
    sys.exit(0 if success else 1)