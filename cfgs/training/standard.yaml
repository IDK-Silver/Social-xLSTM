# Development Training Configuration
# Fast iteration with PyTorch Lightning standards
# Decoupled from model architecture and data parameters

trainer:
  # Core training parameters - using PyTorch Lightning 2.x naming
  max_epochs: 50            # Number of training epochs (not 'epochs')
  accelerator: "auto"       # Let Lightning choose GPU/CPU automatically
  precision: "32-true"      # Use PyTorch Lightning 2.x precision format
  devices: 1                # Number of devices to use
  
  # Development settings - no complex features per CLAUDE.md principles
  enable_progress_bar: true
  log_every_n_steps: 10
  check_val_every_n_epoch: 1

optimizer:
  # Adam optimizer configuration
  name: "Adam"
  lr: 0.001
  weight_decay: 0.0
  betas: [0.9, 0.999]
  eps: 1.0e-08

# No scheduler for simplicity - following extreme minimalism principle
# scheduler: null

experiment:
  # Experiment tracking configuration
  name: "dev_multi_vd"
  save_dir: "logs"
  seed: 42                  # Reproducibility seed

# No callbacks for now - following CLAUDE.md development principles
# - No EarlyStopping
# - No complex monitoring
# - Core functionality first