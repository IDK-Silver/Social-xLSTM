# Social-xLSTM Development/Testing Configuration
# Optimized for fast development and testing with small datasets

# Storage configuration - same as production
storage:
  cold_storage:
    raw_zip:
      type: zip
      folders:
        - /home/GP/dataset/collect/cold_storage

# Dataset preprocessing - optimized for development
dataset:
  pre-processed:
    raw_zip_list:
      type: txt-list
      log:  "logs/dev/pre-processed/raw_zip_list.log"
      file: "blob/dataset/pre-processed/raw_zip_list.txt"
    
    unzip_to_json:
      type:       json
      status:     "blob/status/dev_unzip_to_json.json"
      log:        "logs/dev/pre-processed/unzip_to_json.log"
      folder:     "blob/dataset/pre-processed/unzip_to_json"

    # Small development dataset
    h5:
      file: "blob/dataset/pre-processed/h5/traffic_features_dev.h5"
      log: "logs/dev/create_h5_file.log"
      selected_vdids: ["VD-11-0020-002-001", "VD-28-0740-000-001", "VD-13-0660-000-002"]
      time_range: "2025-03-18_00-49-00,2025-03-18_02-00-00"  # About 1 hour for fast testing
      overwrite: true

# Development training configuration - fast and lightweight
training:
  single_vd:
    experiment_dir: "blob/experiments/dev/single_vd_without_social_pooling"
    log: "logs/dev/train_single_vd_without_social_pooling.log"
    epochs: 2           # Quick training
    batch_size: 4       # Small batches
    sequence_length: 5
    model_type: "lstm"
    select_vd_id: "VD-11-0020-002-001"
  
  multi_vd:
    experiment_dir: "blob/experiments/dev/multi_vd_without_social_pooling"
    log: "logs/dev/train_multi_vd_without_social_pooling.log"
    epochs: 2
    batch_size: 4
    sequence_length: 5
    num_vds: 3          # All 3 VDs in dev dataset
    model_type: "lstm"
  
  independent_multi_vd:
    experiment_dir: "blob/experiments/dev/independent_multi_vd_without_social_pooling"
    log: "logs/dev/train_independent_multi_vd_without_social_pooling.log"
    epochs: 2
    batch_size: 4
    sequence_length: 5
    num_vds: 3
    target_vd_index: 0
    model_type: "lstm"