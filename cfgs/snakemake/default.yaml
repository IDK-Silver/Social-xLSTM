# Social-xLSTM Project Configuration File
# This file contains all configuration parameters for the data processing pipeline and model training
# All paths are relative to the project root directory

# Storage configuration for raw data sources
storage:
  cold_storage:
    raw_zip:
      type: zip  # File type: zip archives containing traffic XML data
      folders:   # List of directories containing raw ZIP files
        - /home/GP/dataset/collect/cold_storage

# Dataset preprocessing pipeline configuration
dataset:
  pre-processed:
    # Step 1: List all ZIP files from the source directories
    raw_zip_list:
      type: txt-list  # Output format: text file with one ZIP path per line
      log:  "logs/default/pre-processed/raw_zip_list.log"  # Log file for this step
      file: "blob/dataset/pre-processed/raw_zip_list.txt"  # Output file containing ZIP list
    
    # Step 2: Extract ZIP files and convert XML to JSON format
    unzip_to_json:
      type:       json  # Output format: JSON files
      status:     "blob/status/default_unzip_to_json.json"  # Status tracking file for extraction progress
      log:        "logs/default/pre-processed/unzip_to_json.log"  # Log file for extraction process
      folder:     "blob/dataset/pre-processed/unzip_to_json"  # Output directory for JSON files

    # Step 3: Create HDF5 dataset from JSON files
    h5:
      file: "blob/dataset/pre-processed/h5/traffic_features_default.h5"  # Output HDF5 file path
      log: "logs/default/create_h5_file.log"  # Log file for HDF5 creation
      selected_vdids: null  # List of VD IDs to include (null = all VDs)
      time_range: null      # Time range filter in format "YYYY-MM-DD,YYYY-MM-DD" (null = all dates)
      overwrite: false      # Whether to overwrite existing HDF5 file

# Model training configuration
training_lstm:
  # Single VD training configuration (no spatial relationships)
  single_vd:
    experiment_dir: "blob/experiments/lstm/single_vd"  # Output directory for experiment results
    log: "logs/train_single_vd_lstm.log"  # Training log file
    epochs: 5           # Number of training epochs
    batch_size: 1       # Batch size for training
    sequence_length: 5  # Length of input time sequences
    model_type: "lstm"  # Model architecture: "lstm" or "xlstm"
    select_vd_id: null  # Specific VD ID to train on (null = first VD in dataset)
  
  # Multi-VD training configuration (processes multiple VDs independently)
  multi_vd:
    experiment_dir: "blob/experiments/lstm/multi_vd"  # Output directory for experiment results
    log: "logs/train_multi_vd_lstm.log"  # Training log file
    epochs: 5           # Number of training epochs
    batch_size: 1       # Batch size for training
    sequence_length: 5  # Length of input time sequences
    num_vds: 1          # Number of VDs to process (1 = same as single VD mode)
    model_type: "lstm"  # Model architecture: "lstm" or "xlstm"
  
  # Independent multi-VD training (uses multiple VDs as input, predicts single target VD)
  independent_multi_vd:
    experiment_dir: "blob/experiments/lstm/independent_multi_vd"  # Output directory
    log: "logs/train_independent_multi_vd_lstm.log"  # Training log file
    epochs: 5           # Number of training epochs
    batch_size: 1       # Batch size for training
    sequence_length: 5  # Length of input time sequences
    num_vds: 1          # Number of input VDs (1 = uses only target VD as input)
    target_vd_index: 0  # Index of the VD to predict (0-based)
    model_type: "lstm"  # Model architecture: "lstm" or "xlstm"

# xLSTM Training Configuration - Extended LSTM experiments for production
training_xlstm:
  # Single VD xLSTM training
  single_vd:
    experiment_dir: "blob/experiments/xlstm/single_vd"
    log: "logs/train_single_vd_xlstm.log"
    epochs: 5           # Same as LSTM for fair comparison
    batch_size: 1       # Same as LSTM for fair comparison
    sequence_length: 5  # Same as LSTM for fair comparison
    model_type: "xlstm"
    select_vd_id: null  # Use first VD by default
    # xLSTM specific parameters - production settings
    embedding_dim: 128
    num_blocks: 6
    slstm_at: [1, 3]
    context_length: 256
    dropout: 0.1
    backend: "vanilla"
  
  # Multi-VD xLSTM training
  multi_vd:
    experiment_dir: "blob/experiments/xlstm/multi_vd"
    log: "logs/train_multi_vd_xlstm.log"
    epochs: 5           # Same as LSTM for fair comparison
    batch_size: 1       # Same as LSTM for fair comparison
    sequence_length: 5  # Same as LSTM for fair comparison
    model_type: "xlstm"
    num_vds: 3          # Use multiple VDs
    # xLSTM specific parameters - production settings
    embedding_dim: 128
    num_blocks: 6
    slstm_at: [1, 3]
    context_length: 256
    dropout: 0.1
    backend: "vanilla"